{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "678c0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy, Compose\n",
    "\n",
    "from hyperparams_explore import hp_categorical\n",
    "from models import ResNet18, DenseNet121, PreActResNet18\n",
    "from transforms import cutout, gaussian_noise, hide_and_seek\n",
    "from utils import (\n",
    "    DEFAULT_TRANSFORMS,\n",
    "    get_device,\n",
    "    get_optimiser,\n",
    "    get_scheduler,\n",
    "    get_hyperparams,\n",
    "    get_cifar10_train_val_loaders,\n",
    "    test,\n",
    "    train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafe223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_res = {\n",
    "    \"params\": {'userotation': False, 'usetranslation': False, 'useshearing': True, 'usehorizontal_flip': True, 'usevertical_flip': False, 'usecrop': False, 'usecolor_jitter': False, 'usenoise_injection': False, 'usekernel': False, 'userandom_erasing': False, 'usecutout': False, 'usehide_and_seek': False},\n",
    "    \"value\": 87.58,\n",
    "}\n",
    "from utils import pickle_dump\n",
    "\n",
    "pickle_dump(trial_res, \"transforms_best_trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d3895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Trial 13 finished with value: 87.58 and parameters: {'userotation': False, 'usetranslation': False, 'useshearing': True, 'usehorizontal_flip': True, 'usevertical_flip': False, 'usecrop': False, 'usecolor_jitter': False, 'usenoise_injection': False, 'usekernel': False, 'userandom_erasing': False, 'usecutout': False, 'usehide_and_seek': False}. Best is trial 13 with value: 87.58.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Trial 13 finished with value: 87.58 and parameters: {'userotation': False, 'usetranslation': False, 'useshearing': True, 'usehorizontal_flip': True, 'usevertical_flip': False, 'usecrop': False, 'usecolor_jitter': False, 'usenoise_injection': False, 'usekernel': False, 'userandom_erasing': False, 'usecutout': False, 'usehide_and_seek': False}. Best is trial 13 with value: 87.58.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd1abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_degree = 45\n",
    "translation = (0.2, 0.2) \n",
    "shearing = (10, 20, 0, 10)  # horizontal shear: 10–20°, vertical shear: 0–10°\n",
    "kernel_size = 5\n",
    "CUTOUT_SIZE = 16\n",
    "CUTOUT_PROB = 1\n",
    "\n",
    "transformations = {\n",
    "    # Geometric\n",
    "    \"rotation\": transforms.RandomRotation(rotation_degree),\n",
    "    \"translation\": transforms.RandomAffine(degrees=0, translate=translation),\n",
    "    \"shearing\": transforms.RandomAffine(degrees=0, shear=shearing),\n",
    "\n",
    "    # Non geometric\n",
    "    \"horizontal_flip\": transforms.RandomHorizontalFlip(),\n",
    "    \"vertical_flip\": transforms.RandomVerticalFlip(),\n",
    "    \"crop\": transforms.RandomCrop(32, padding=4),\n",
    "    \"color_jitter\": transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    \"noise_injection\": gaussian_noise,\n",
    "    \"kernel\": transforms.GaussianBlur(kernel_size=kernel_size),\n",
    "\n",
    "    # Erasing\n",
    "    \"random_erasing\": transforms.RandomErasing(),\n",
    "    \"cutout\": cutout(mask_size=CUTOUT_SIZE, p=CUTOUT_PROB),\n",
    "    \"hide_and_seek\": hide_and_seek,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb50a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from utils import ROOT_DIR\n",
    "import numpy as np\n",
    "\n",
    "dataset = CIFAR10(root=ROOT_DIR, train=True, download=True, transform=None)\n",
    "\n",
    "image, label = dataset[0]  # image is already a PIL.Image.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b3ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDiNHsJ7GBpGkcyuTncxP5VcuL77Kd1xNIN6jgueTV/Vp47VA4jQsW2qBwM1a0rwjH4guoJrlzFJOhaGF+gUYCn8TmvKcm3d9T00klZdDJjv9k5t51nSUjdtbI7defan3+pXlrHsjE0rYyNr9vxrtb/AOHEsiyJMj3FyUxEWfbg/wBa5Wa1kspWtbgbZYTsYHsRxQmtGN8uyZLaQ2tzqMX9oiQ2iS732KC3XoP89K7a+1ZreS71HT7WJUCxJA7Dd5arwRj/ADyawLjR5DdPNYFmjDElAD61UN5qkKypvmUMR8u0jkcVjTrKashuKubdp4tljvlu9UeSeJPmUhgu1/b0HasG6ln1fWnkhZDb3M2UV+4J5qlOiiIGeLeM/MhBIz649afFqLRWuqtZWUs1xBCixkqQihjg49wKc1KasZyjbY//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJgklEQVR4ARVW2a7cWBU9o31sl13TreFOyU1yc0NoddLQAbXC2OoXeEG88XfwAwihFkJC4qGFBDzQrSCahCZkvmPdmlxl+9g+IztHKpVKtnbts/baay38gx//JM9XIXGDwN8YxqNBstPrBJSzMEKUrda5Mr7f6xKr27ZtmkZEwiIr67Lby5C3qlUUcUpp2ukkScK5qFvlMUGEwSPjMXv67Gm+WAwEwkOxY1McjSu3Kq33OJCNknWrrVtQLJg3xlHCwjCUTWWcws2QUAR/GzFRtmplTRwnmHBMOSJENtpoTVnIIoZRiG4OxdGkOx4NIngJ4xp61a3HOIgiZLx3bXcQG+0DHlmLaBC2CgrgOAhZEokgNLgi3hmEKUadJC4rCeUJRsV2wwQ2acpO9vvDiHLXlCtlHamlIQHKeh0WhPmmYAwN0rjYVqqp6kZ7hAEOrWpiGQ9DazWjuG11wAPiTFuukfUhRca5TdWyPlwiDLtJNMq4ddAfIE/hjq3TDI53tq09JdfXudW2kFJa1Yky1FqKHMGehqKumphnzPumUbU2Dvm8bHKpS2kaTdioJ1JOhaCE+iiKtLEOYe8VDMgq7byGL8+CQlXWUmkdPC8qfb6qOHFZifXVot7IGzvH4/EBTjftelmW1aZoFpv6zenGUsb2RkkWmE4cYK8R8hjwriWBkafdJBHbzaKbZUWj354vypYGDu3HjPH6zTJvPeXYd7P08bcfbS+tl767w1vJypKEnB9O0/F4Mts2bJBGTOUhZ3EYt7XWzvR6fQ9XsETrJu50Lubty7ebeWGkQTcj+ssffXSw2/ntV6/+/uIKuMSIL/K5LNs05chiIXggaIy5sebG4V66Kth4MKxXDcGslLpWhmEqtSUI1Vr1+pmy/tXZxWprASVKSSbsmBVi1d7NppcDMsuvW6mePH9OjNNJhroToH+3G6fON0p7tT0aJay/M+p3IkJ4vl3rqiQWZuA8Z52O0Ej859Xzqq2ECEXAoiTuU/PVi5lRrO1OR32BUaZNI1VdSa+MwVohjDiMnsCiMtO2HhpDsBqcI4RCwWOUwG84Grkw6i6uCrlY3x6ItkEiie/d2SdtYyjfbteMbtIgGfbv3Ll74/W7f3zz/DxgrfelMYwwoCt3cBBsFGHAa6xrhExVbZUmhohSFltZ7B/C7hY3d/CdPS4bvH/yMPDNeqOj3hAt6eF0N6+q29+6m/XjrH9/PS/Wmw0PEuJD7SzUttrAosEsmcXWW1hWH4mok8YX8/r12ZxxH8wumtn87ph/9tO7L89X6f5oZzi9ns96vYQ42Ch6PT9nIp/nl+eXJedxL3N1DfUIJtg5S953T6xHrNfrGGbKsvHaborN23ezsiwjQS5fbyci2N+/2du7xQuHBD94+H1xdR6ZuUVNVTW78QiWHiedg2Qv7U2L5dX1bKkxb1SLiE9CoeoSsGJFvmSq4KB/FDFKZbnpp0kvEfV6O94b7j/4yb/P1PMX6vHuIM/V5M5DgqRq5z3vttfLSOndwSC3IX/Qr/PLv/7x87PTOQ1gorj2SMM49XsVQbYuQV4IMhbTtUbbrfet2u0m3/v004N7n/zuN7+eJh2q6vNXL6e3vy2Gx4kv5Oo6cn1Vy0Uhe6Nbw+lRXWYkQzZoACKtFYZiAL1hDHsYiAa8GEG+1tihwTCexua7j07uP/5kfV2GZnP74MBhNx2PTGNkDipidM0s6rw8P/v6318+/kQNp8NtcQ0s3DlKHECvrGnVZp63RcxAXOrWBUkHFIASdTzti4gc3Tx8+MNPd+89+Offf3PjsD/94MNgdIfFXdmU9baYXZyuZ2dWyygVOzv89OLJZHffyNLXLa7W1tcgOFHIgynfhhiqsnUhbYOjOKLEj4fx6WV+57s/O/jwZwj1dVF10+7o5KOKDZ4++UdbV9ttvjh/R60Sgu3f2n9wcmxowmmPB5o1jXx7Dh0bgkpK42Ey2Ruytm7ikGFBOQH9NFGH/uJXv3j888+yncns1X8oMXmxmb/570Vhv/j97zsRb9pyOgGJS16fnSpiBntHJx9+jGy4ys9gXda1wZ41tSuB+GVzv4eY8wo5i40zXmPsRZh99PHHIIfP/vlkffESbLhYr05fPCt9xG3TYTQTyajfvZxdgSPKojx9/Q6hp2VZvPfUcLw0WRSJOI0iFhZyC1UZQs6BuPDYGquQmXT7f/r8D4PJ0/HuoZIbzsNOkjECKPDpeFgX64iGy/lCK5uKSJXl/558efnN89bU4PwWXjtIUKJI2Ahn+ii6/8Et5hwOGBXMoff+lDilF4urcn4V6a1DdNAf9vZGxrbnF1ceeeAaUIhinogYrIvCB8ioNsThrVyrsE732irKCwfeSobZ7Z3xkBAcijDyyMSRGA/HXrfDNOiGRm1mqlhIWYTZgCTDew8eORYpD6XAUqSzKKBMcGaMeX42//LZxdcvL1dmK3qMB0FZmqr2STqspSUBI6ptnQ8cDcERKHWxiJJ0FMTdyXinWM+l0qPDY+nCD773g/sfPSJMVGUrZQ1ig5G7PL949/qqlHXUgUw1xg3Hl0n/eudE3DroHbx4dsUmI6KXy9q6qgIILPh8lg0DzoGQEWdIsS//9rfb92ZnZ1dw2TiEjBVGUVKVNRxjIACEj79zItLMUAObUZ82pBDjOP3OyQfj3uSry9fsxmHQxeLFqZzNwSbDTodVcmNdCcliNV8WJSSDDfWbtNOfXa3OqsZ5PBkNsdPrfB0mYa+bBpS0yiLGq5aoksMqHx9O96bD07PZci5Z1uf1XPbHFCXxYtY2SrEgU0BdDTGl3dTrJAob2dTNQmlIQBD5aLmVWRZlWbcGLVquITOC0mDjwfRCgYKAHh0f1dL/5S/P/vX8mjHBRBYMOmA9LY8cmBWyBOZtOSSiPIgZf+/GceuBXwoCJWiXV41tEGccQSxbr2ulIacyMEIWSGRmi2JdmqLa/PmLb2YSASU4otBEw6P3It7tunJbl9tZKa1ubBoMBefgroyRgCAeUvCRuAO+CNprgohlvXi1KgrvssFQGvW/N8tvvj6dDLLJQYyI2+mm7OwtanORjoyIdLeDBgMGyTLP5XoZrJeIOuq8txD4wKRA5gmGKFVb4g3iThu5ssBExvNSwhRW2/rNi2W+rCCkTbvT+zf3tzVilu/o4FHrWmIWoot7I9EHhZEuX0X5gtYVg0aBXs44mEMAADNaNK4uG+5VSlJHtmAqYeIFD3uBuo16Hz5M7j14eHR8/P1P5NlF+X8Wt9uThtmfRQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f8d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKACiiigAooooA//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAJUlEQVR4Ae3QMQEAAADCoPVP7WENiEBhwIABAwYMGDBgwICBDwwMIAABisM/AAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_and_seek(transforms.ToImage()(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8810c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-23 21:40:17,866] A new study created in memory with name: no-name-8d958b48-9e0e-4b19-ba42-fe262e8d759e\n",
      "[W 2025-04-23 21:40:30,520] Trial 0 failed with parameters: {'userotation': True, 'usetranslation': True, 'useshearing': True, 'usehorizontal_flip': False, 'usevertical_flip': True, 'usecrop': False, 'usecolor_jitter': True, 'usenoise_injection': True, 'usekernel': True, 'userandom_erasing': False, 'usecutout': False, 'usehide_and_seek': False} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3642248/3170120209.py\", line 7, in <lambda>\n",
      "    lambda x: objective(x, chosen_model, hp_params, n_epochs),\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3642248/2718117664.py\", line 46, in objective\n",
      "    train_acc, train_loss = train(train_loader, model, optimiser, criterion, device)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/users/local/b24richa/EDL/utils.py\", line 114, in train\n",
      "    train_loss += loss.item()\n",
      "                  ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-23 21:40:30,521] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m chosen_model = DenseNet121\n\u001b[32m      5\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest trial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_trial.params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      3\u001b[39m chosen_model = DenseNet121\n\u001b[32m      5\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m      6\u001b[39m study.optimize(\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m      8\u001b[39m     n_trials=\u001b[32m10\u001b[39m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest trial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_trial.params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, model_class, hp_params, n_epochs)\u001b[39m\n\u001b[32m     44\u001b[39m best_val_acc = \u001b[32m0\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     train_acc, train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     val_acc, val_loss = test(val_loader, model, criterion, device)\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m s_name == \u001b[33m\"\u001b[39m\u001b[33mReduceLROnPlateau\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/utils.py:114\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, net, optimiser, criterion, device)\u001b[39m\n\u001b[32m    111\u001b[39m loss.backward()\n\u001b[32m    112\u001b[39m optimiser.step()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m    116\u001b[39m total += targets.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "hp_params = get_hyperparams()\n",
    "chosen_model = DenseNet121\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\") \n",
    "study.optimize(\n",
    "    lambda x: objective(x, chosen_model, hp_params, n_epochs),\n",
    "    n_trials=10,\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best trial: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b1999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfbd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userotation': True,\n",
       " 'usetranslation': False,\n",
       " 'useshearing': False,\n",
       " 'usehorizontal_flip': False,\n",
       " 'usevertical_flip': False,\n",
       " 'usecrop': False,\n",
       " 'usecolor_jitter': False,\n",
       " 'usekernel': False,\n",
       " 'userandom_erasing': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2f0bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m best_val_acc = \u001b[32m0\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     train_acc, train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     val_acc, val_loss = test(val_loader, model, criterion, device)\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m s_name == \u001b[33m\"\u001b[39m\u001b[33mReduceLROnPlateau\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/utils.py:114\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_loader, net, optimiser, criterion, device)\u001b[39m\n\u001b[32m    111\u001b[39m loss.backward()\n\u001b[32m    112\u001b[39m optimiser.step()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m    116\u001b[39m total += targets.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy, Compose\n",
    "\n",
    "from hyperparams_explore import hp_categorical\n",
    "from models import DenseNet121\n",
    "from utils import (\n",
    "    DEFAULT_TRANSFORMS,\n",
    "    get_cifar10_train_val_loaders,\n",
    "    get_device, get_hyperparams,\n",
    "    get_optimiser, get_scheduler,\n",
    "    pickle_dump,\n",
    "    test,\n",
    "    train,\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    n_epochs = 20\n",
    "    hp_params = get_hyperparams()\n",
    "    chosen_model = DenseNet121\n",
    "\n",
    "    autoaugment_transform = Compose([\n",
    "        AutoAugment(policy=AutoAugmentPolicy.CIFAR10),\n",
    "        *DEFAULT_TRANSFORMS,\n",
    "    ])\n",
    "    train_loader, val_loader = get_cifar10_train_val_loaders(transform=autoaugment_transform)\n",
    "\n",
    "    model = chosen_model()\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "    \n",
    "    optimiser = get_optimiser(\n",
    "        hp_params[\"optimizer\"],\n",
    "        model.parameters(),\n",
    "        lr=hp_params[\"lr\"],\n",
    "        weight_decay=hp_params[\"weight_decay\"]\n",
    "    )\n",
    "    s_name = hp_params[\"lr_scheduler\"]\n",
    "    scheduler = get_scheduler(\n",
    "        s_name,\n",
    "        optimiser,\n",
    "        **hp_categorical[\"lr_schedulers\"][\"params\"][s_name]\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        train_acc, train_loss = train(train_loader, model, optimiser, criterion, device)\n",
    "        val_acc, val_loss = test(val_loader, model, criterion, device)\n",
    "\n",
    "        if s_name == \"ReduceLROnPlateau\":\n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "\n",
    "    auto_augment_acc = {\"autoaugment_acc\": best_val_acc}\n",
    "    pickle_dump(auto_augment_acc, \"autoaugment_acc\")\n",
    "\n",
    "    print(\"RUN SUCESS AUGO AUGMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3863fe2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    232\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    233\u001b[39m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[32m    234\u001b[39m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[32m    235\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    236\u001b[39m                 collate(samples, collate_fn_map=collate_fn_map)\n\u001b[32m    237\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    238\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format.format(elem_type))\n",
      "\u001b[31mTypeError\u001b[39m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "for i, t in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171667e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
