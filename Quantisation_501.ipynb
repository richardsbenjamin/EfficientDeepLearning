{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1aa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from binaryconnect import BC\n",
    "from models import DenseNet121\n",
    "from utils import get_device, get_model_size_mb, get_test_cifar10_dataloader, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b25eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import dtype as T_dtype\n",
    "from torch.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "QCONFIG = get_default_qconfig('fbgemm')\n",
    "QCONFIG_DEFAULT = {\n",
    "    \"\": QCONFIG,\n",
    "    \"object_type\": [\n",
    "        (torch.nn.Conv2d, QCONFIG),\n",
    "        (torch.nn.Linear, QCONFIG),\n",
    "        (torch.nn.ReLU, QCONFIG),\n",
    "        (torch.nn.BatchNorm2d, QCONFIG),\n",
    "    ]\n",
    "}\n",
    "\n",
    "def quantise_dynamic(\n",
    "        model: nn.Module,\n",
    "        spec: tuple = {torch.nn.Linear},\n",
    "        dtype: T_dtype = torch.qint8,\n",
    "    ) -> nn.Module:\n",
    "    return torch.quantization.quantize_dynamic(\n",
    "        model, spec, dtype=dtype,\n",
    "    )\n",
    "\n",
    "def quantise_static(\n",
    "        model: nn.Module,\n",
    "        calibration_loader: DataLoader,\n",
    "        qconfig_dict: dict = QCONFIG_DEFAULT,\n",
    "    ) -> nn.Module:\n",
    "    model = model.to('cpu')\n",
    "    example_inputs = (next(iter(calibration_loader))[0],)\n",
    "    prepared_model = prepare_fx(model, qconfig_dict, example_inputs)\n",
    "    return convert_fx(prepared_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "device = get_device()\n",
    "\n",
    "with open(\"train_results.pkl\", \"rb\") as f:\n",
    "    res = pickle.load(f)\n",
    "state_dict, acc, train_accs, val_accs = res.values()\n",
    "\n",
    "model = DenseNet121()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d334bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_test_cifar10_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88004bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60819116",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_acc, _ = test(\n",
    "    test_loader,\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a68e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fd00b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.353676"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_size = get_model_size_mb(model)\n",
    "og_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add31ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.313666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "dynamic_quantised_model = torch.quantization.quantize_dynamic(\n",
    "        model, {torch.nn.Linear}, dtype=torch.qint8,\n",
    "    )\n",
    "dynamic_quantised_size = get_model_size_mb(dynamic_quantised_model)\n",
    "dynamic_quantised_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286ee631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"thinet_prune_half_quant.pkl\", \"rb\") as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab25380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2, 18.31, 0.7322058681589754, 5630117),\n",
       " (0.3, 10.0, 0.6092079834848477, 4951368),\n",
       " (0.4, 10.0, 0.4956531306144839, 4272135),\n",
       " (0.5, 10.08, 0.38176272222580515, 3525034)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea523b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = [r[1] for r in res]\n",
    "y = [r[2] for r in res]\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "for i, (xi, yi) in enumerate(zip(x, y)):\n",
    "    plt.text(xi, yi, f\"{res[i][0]}\", fontsize=8, ha='left', va='top')\n",
    "\n",
    "\n",
    "plt.title(\"ThiNet Pruning Half Quant. Accuracy v Score\")\n",
    "plt.xlabel(\"Accuracy (%)\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cb257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66584f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_quantised_acc, _ = test(\n",
    "    test_loader,\n",
    "    dynamic_quantised_model,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d74cc031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.38"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_quantised_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3daa99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
      "  prepared = prepare(\n",
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1318: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.89627"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() \n",
    "static_quantised_model = quantise_static(model, test_loader)\n",
    "static_quantised_size = get_model_size_mb(static_quantised_model)\n",
    "static_quantised_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe0cf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quantised_model = static_quantised_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9a82e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quantised_acc, _ = test(\n",
    "    test_loader,\n",
    "    static_quantised_model,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a425e72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_quantised_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d43ca38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.27406"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "half_model = model.half()\n",
    "half_model_size = get_model_size_mb(half_model)\n",
    "half_model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a20171f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_model_acc, _ = test(\n",
    "    test_loader,\n",
    "    half_model,\n",
    "    half=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e420392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79033fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_best_transformations, get_cifar10_train_val_loaders, load_untrained_model, run_epochs, get_dataloader, get_train_cifar10_dataset\n",
    "\n",
    "train_transforms = get_best_transformations()\n",
    "training_details = load_untrained_model(\"DenseNet121\")\n",
    "# train_loader, val_loader = get_cifar10_train_val_loaders()\n",
    "train_loader = get_dataloader(get_train_cifar10_dataset(subset=True, num_subset=1000))\n",
    "val_loader = get_dataloader(get_train_cifar10_dataset(subset=True, num_subset=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f046a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "# model.to(\"cpu\")\n",
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "torch.quantization.prepare_qat(model, inplace=True)\n",
    "\n",
    "best_acc, train_accs, test_accs = run_epochs(\n",
    "    training_details[\"model\"],\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    training_details,\n",
    "    n_epochs=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d32bae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "qat_model = torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30567048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.07959"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_size_mb(qat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c36e9069",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:2045 [kernel]\nQuantizedCUDA: registered at /pytorch/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]\nTracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# qat_model.to(\"cpu\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m qat_acc, _ = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqat_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/utils.py:197\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(test_loader, net, criterion, device, half)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m half:\n\u001b[32m    195\u001b[39m     inputs = inputs.half()\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m outputs = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m loss = criterion(outputs, targets)\n\u001b[32m    200\u001b[39m test_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/models/densenet.py:76\u001b[39m, in \u001b[36mDenseNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.trans1(\u001b[38;5;28mself\u001b[39m.dense1(out))\n\u001b[32m     78\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.trans2(\u001b[38;5;28mself\u001b[39m.dense2(out))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:594\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    590\u001b[39m     _reversed_padding_repeated_twice = _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m.padding)\n\u001b[32m    591\u001b[39m     \u001b[38;5;28minput\u001b[39m = F.pad(\n\u001b[32m    592\u001b[39m         \u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m    593\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantized\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzero_point\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/_ops.py:1123\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:2045 [kernel]\nQuantizedCUDA: registered at /pytorch/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]\nTracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# qat_model.to(\"cpu\")\n",
    "qat_acc, _ = test(\n",
    "    test_loader,\n",
    "    qat_model,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13a0f3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (conv1): QuantizedConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans1): Transition(\n",
       "    (bn): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans2): Transition(\n",
       "    (bn): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantizedConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans3): Transition(\n",
       "    (bn): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv): QuantizedConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (bn1): QuantizedBatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): QuantizedConv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
       "      (bn2): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn): QuantizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear): QuantizedLinear(in_features=1024, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703468e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
      "  prepared = prepare(\n",
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1318: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): QuantizedConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "  (dense1): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(96, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(160, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(192, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(224, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans1): Module(\n",
      "    (bn): QuantizedBNReLU2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "  )\n",
      "  (dense2): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(160, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(192, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(224, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(288, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Module(\n",
      "      (bn1): QuantizedBNReLU2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(320, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Module(\n",
      "      (bn1): QuantizedBNReLU2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(352, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Module(\n",
      "      (bn1): QuantizedBNReLU2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(384, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Module(\n",
      "      (bn1): QuantizedBNReLU2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(416, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Module(\n",
      "      (bn1): QuantizedBNReLU2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(448, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Module(\n",
      "      (bn1): QuantizedBNReLU2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(480, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans2): Module(\n",
      "    (bn): QuantizedBNReLU2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): QuantizedConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "  )\n",
      "  (dense3): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(288, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(320, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(352, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(384, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(416, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Module(\n",
      "      (bn1): QuantizedBNReLU2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(448, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Module(\n",
      "      (bn1): QuantizedBNReLU2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(480, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Module(\n",
      "      (bn1): QuantizedBNReLU2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Module(\n",
      "      (bn1): QuantizedBNReLU2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(544, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Module(\n",
      "      (bn1): QuantizedBNReLU2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(576, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Module(\n",
      "      (bn1): QuantizedBNReLU2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(608, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Module(\n",
      "      (bn1): QuantizedBNReLU2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(640, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Module(\n",
      "      (bn1): QuantizedBNReLU2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(672, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Module(\n",
      "      (bn1): QuantizedBNReLU2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(704, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Module(\n",
      "      (bn1): QuantizedBNReLU2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(736, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (16): Module(\n",
      "      (bn1): QuantizedBNReLU2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (17): Module(\n",
      "      (bn1): QuantizedBNReLU2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(800, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (18): Module(\n",
      "      (bn1): QuantizedBNReLU2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(832, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (19): Module(\n",
      "      (bn1): QuantizedBNReLU2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(864, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (20): Module(\n",
      "      (bn1): QuantizedBNReLU2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(896, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (21): Module(\n",
      "      (bn1): QuantizedBNReLU2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(928, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (22): Module(\n",
      "      (bn1): QuantizedBNReLU2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(960, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (23): Module(\n",
      "      (bn1): QuantizedBNReLU2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(992, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans3): Module(\n",
      "    (bn): QuantizedBNReLU2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): QuantizedConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "  )\n",
      "  (dense4): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(544, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(576, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(608, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(640, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(672, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Module(\n",
      "      (bn1): QuantizedBNReLU2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(704, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Module(\n",
      "      (bn1): QuantizedBNReLU2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(736, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Module(\n",
      "      (bn1): QuantizedBNReLU2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Module(\n",
      "      (bn1): QuantizedBNReLU2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(800, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Module(\n",
      "      (bn1): QuantizedBNReLU2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(832, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Module(\n",
      "      (bn1): QuantizedBNReLU2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(864, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Module(\n",
      "      (bn1): QuantizedBNReLU2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(896, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Module(\n",
      "      (bn1): QuantizedBNReLU2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(928, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Module(\n",
      "      (bn1): QuantizedBNReLU2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(960, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Module(\n",
      "      (bn1): QuantizedBNReLU2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(992, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (bn): QuantizedBNReLU2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear): QuantizedLinear(in_features=1024, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1_input_scale_0 = self.conv1_input_scale_0\n",
      "    conv1_input_zero_point_0 = self.conv1_input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(x, conv1_input_scale_0, conv1_input_zero_point_0, torch.quint8);  x = conv1_input_scale_0 = conv1_input_zero_point_0 = None\n",
      "    conv1 = self.conv1(quantize_per_tensor);  quantize_per_tensor = None\n",
      "    dense1_0_bn1 = getattr(self.dense1, \"0\").bn1(conv1)\n",
      "    dense1_0_conv1 = getattr(self.dense1, \"0\").conv1(dense1_0_bn1);  dense1_0_bn1 = None\n",
      "    dense1_0_conv2 = getattr(self.dense1, \"0\").conv2(dense1_0_conv1);  dense1_0_conv1 = None\n",
      "    cat = torch.cat([dense1_0_conv2, conv1], 1);  dense1_0_conv2 = conv1 = None\n",
      "    dense1_1_bn1 = getattr(self.dense1, \"1\").bn1(cat)\n",
      "    dense1_1_conv1 = getattr(self.dense1, \"1\").conv1(dense1_1_bn1);  dense1_1_bn1 = None\n",
      "    dense1_1_conv2 = getattr(self.dense1, \"1\").conv2(dense1_1_conv1);  dense1_1_conv1 = None\n",
      "    cat_1 = torch.cat([dense1_1_conv2, cat], 1);  dense1_1_conv2 = cat = None\n",
      "    dense1_2_bn1 = getattr(self.dense1, \"2\").bn1(cat_1)\n",
      "    dense1_2_conv1 = getattr(self.dense1, \"2\").conv1(dense1_2_bn1);  dense1_2_bn1 = None\n",
      "    dense1_2_conv2 = getattr(self.dense1, \"2\").conv2(dense1_2_conv1);  dense1_2_conv1 = None\n",
      "    cat_2 = torch.cat([dense1_2_conv2, cat_1], 1);  dense1_2_conv2 = cat_1 = None\n",
      "    dense1_3_bn1 = getattr(self.dense1, \"3\").bn1(cat_2)\n",
      "    dense1_3_conv1 = getattr(self.dense1, \"3\").conv1(dense1_3_bn1);  dense1_3_bn1 = None\n",
      "    dense1_3_conv2 = getattr(self.dense1, \"3\").conv2(dense1_3_conv1);  dense1_3_conv1 = None\n",
      "    cat_3 = torch.cat([dense1_3_conv2, cat_2], 1);  dense1_3_conv2 = cat_2 = None\n",
      "    dense1_4_bn1 = getattr(self.dense1, \"4\").bn1(cat_3)\n",
      "    dense1_4_conv1 = getattr(self.dense1, \"4\").conv1(dense1_4_bn1);  dense1_4_bn1 = None\n",
      "    dense1_4_conv2 = getattr(self.dense1, \"4\").conv2(dense1_4_conv1);  dense1_4_conv1 = None\n",
      "    cat_4 = torch.cat([dense1_4_conv2, cat_3], 1);  dense1_4_conv2 = cat_3 = None\n",
      "    dense1_5_bn1 = getattr(self.dense1, \"5\").bn1(cat_4)\n",
      "    dense1_5_conv1 = getattr(self.dense1, \"5\").conv1(dense1_5_bn1);  dense1_5_bn1 = None\n",
      "    dense1_5_conv2 = getattr(self.dense1, \"5\").conv2(dense1_5_conv1);  dense1_5_conv1 = None\n",
      "    cat_5 = torch.cat([dense1_5_conv2, cat_4], 1);  dense1_5_conv2 = cat_4 = None\n",
      "    trans1_bn = self.trans1.bn(cat_5);  cat_5 = None\n",
      "    trans1_conv = self.trans1.conv(trans1_bn);  trans1_bn = None\n",
      "    avg_pool2d = torch._C._nn.avg_pool2d(trans1_conv, 2);  trans1_conv = None\n",
      "    dense2_0_bn1 = getattr(self.dense2, \"0\").bn1(avg_pool2d)\n",
      "    dense2_0_conv1 = getattr(self.dense2, \"0\").conv1(dense2_0_bn1);  dense2_0_bn1 = None\n",
      "    dense2_0_conv2 = getattr(self.dense2, \"0\").conv2(dense2_0_conv1);  dense2_0_conv1 = None\n",
      "    cat_6 = torch.cat([dense2_0_conv2, avg_pool2d], 1);  dense2_0_conv2 = avg_pool2d = None\n",
      "    dense2_1_bn1 = getattr(self.dense2, \"1\").bn1(cat_6)\n",
      "    dense2_1_conv1 = getattr(self.dense2, \"1\").conv1(dense2_1_bn1);  dense2_1_bn1 = None\n",
      "    dense2_1_conv2 = getattr(self.dense2, \"1\").conv2(dense2_1_conv1);  dense2_1_conv1 = None\n",
      "    cat_7 = torch.cat([dense2_1_conv2, cat_6], 1);  dense2_1_conv2 = cat_6 = None\n",
      "    dense2_2_bn1 = getattr(self.dense2, \"2\").bn1(cat_7)\n",
      "    dense2_2_conv1 = getattr(self.dense2, \"2\").conv1(dense2_2_bn1);  dense2_2_bn1 = None\n",
      "    dense2_2_conv2 = getattr(self.dense2, \"2\").conv2(dense2_2_conv1);  dense2_2_conv1 = None\n",
      "    cat_8 = torch.cat([dense2_2_conv2, cat_7], 1);  dense2_2_conv2 = cat_7 = None\n",
      "    dense2_3_bn1 = getattr(self.dense2, \"3\").bn1(cat_8)\n",
      "    dense2_3_conv1 = getattr(self.dense2, \"3\").conv1(dense2_3_bn1);  dense2_3_bn1 = None\n",
      "    dense2_3_conv2 = getattr(self.dense2, \"3\").conv2(dense2_3_conv1);  dense2_3_conv1 = None\n",
      "    cat_9 = torch.cat([dense2_3_conv2, cat_8], 1);  dense2_3_conv2 = cat_8 = None\n",
      "    dense2_4_bn1 = getattr(self.dense2, \"4\").bn1(cat_9)\n",
      "    dense2_4_conv1 = getattr(self.dense2, \"4\").conv1(dense2_4_bn1);  dense2_4_bn1 = None\n",
      "    dense2_4_conv2 = getattr(self.dense2, \"4\").conv2(dense2_4_conv1);  dense2_4_conv1 = None\n",
      "    cat_10 = torch.cat([dense2_4_conv2, cat_9], 1);  dense2_4_conv2 = cat_9 = None\n",
      "    dense2_5_bn1 = getattr(self.dense2, \"5\").bn1(cat_10)\n",
      "    dense2_5_conv1 = getattr(self.dense2, \"5\").conv1(dense2_5_bn1);  dense2_5_bn1 = None\n",
      "    dense2_5_conv2 = getattr(self.dense2, \"5\").conv2(dense2_5_conv1);  dense2_5_conv1 = None\n",
      "    cat_11 = torch.cat([dense2_5_conv2, cat_10], 1);  dense2_5_conv2 = cat_10 = None\n",
      "    dense2_6_bn1 = getattr(self.dense2, \"6\").bn1(cat_11)\n",
      "    dense2_6_conv1 = getattr(self.dense2, \"6\").conv1(dense2_6_bn1);  dense2_6_bn1 = None\n",
      "    dense2_6_conv2 = getattr(self.dense2, \"6\").conv2(dense2_6_conv1);  dense2_6_conv1 = None\n",
      "    cat_12 = torch.cat([dense2_6_conv2, cat_11], 1);  dense2_6_conv2 = cat_11 = None\n",
      "    dense2_7_bn1 = getattr(self.dense2, \"7\").bn1(cat_12)\n",
      "    dense2_7_conv1 = getattr(self.dense2, \"7\").conv1(dense2_7_bn1);  dense2_7_bn1 = None\n",
      "    dense2_7_conv2 = getattr(self.dense2, \"7\").conv2(dense2_7_conv1);  dense2_7_conv1 = None\n",
      "    cat_13 = torch.cat([dense2_7_conv2, cat_12], 1);  dense2_7_conv2 = cat_12 = None\n",
      "    dense2_8_bn1 = getattr(self.dense2, \"8\").bn1(cat_13)\n",
      "    dense2_8_conv1 = getattr(self.dense2, \"8\").conv1(dense2_8_bn1);  dense2_8_bn1 = None\n",
      "    dense2_8_conv2 = getattr(self.dense2, \"8\").conv2(dense2_8_conv1);  dense2_8_conv1 = None\n",
      "    cat_14 = torch.cat([dense2_8_conv2, cat_13], 1);  dense2_8_conv2 = cat_13 = None\n",
      "    dense2_9_bn1 = getattr(self.dense2, \"9\").bn1(cat_14)\n",
      "    dense2_9_conv1 = getattr(self.dense2, \"9\").conv1(dense2_9_bn1);  dense2_9_bn1 = None\n",
      "    dense2_9_conv2 = getattr(self.dense2, \"9\").conv2(dense2_9_conv1);  dense2_9_conv1 = None\n",
      "    cat_15 = torch.cat([dense2_9_conv2, cat_14], 1);  dense2_9_conv2 = cat_14 = None\n",
      "    dense2_10_bn1 = getattr(self.dense2, \"10\").bn1(cat_15)\n",
      "    dense2_10_conv1 = getattr(self.dense2, \"10\").conv1(dense2_10_bn1);  dense2_10_bn1 = None\n",
      "    dense2_10_conv2 = getattr(self.dense2, \"10\").conv2(dense2_10_conv1);  dense2_10_conv1 = None\n",
      "    cat_16 = torch.cat([dense2_10_conv2, cat_15], 1);  dense2_10_conv2 = cat_15 = None\n",
      "    dense2_11_bn1 = getattr(self.dense2, \"11\").bn1(cat_16)\n",
      "    dense2_11_conv1 = getattr(self.dense2, \"11\").conv1(dense2_11_bn1);  dense2_11_bn1 = None\n",
      "    dense2_11_conv2 = getattr(self.dense2, \"11\").conv2(dense2_11_conv1);  dense2_11_conv1 = None\n",
      "    cat_17 = torch.cat([dense2_11_conv2, cat_16], 1);  dense2_11_conv2 = cat_16 = None\n",
      "    trans2_bn = self.trans2.bn(cat_17);  cat_17 = None\n",
      "    trans2_conv = self.trans2.conv(trans2_bn);  trans2_bn = None\n",
      "    avg_pool2d_1 = torch._C._nn.avg_pool2d(trans2_conv, 2);  trans2_conv = None\n",
      "    dense3_0_bn1 = getattr(self.dense3, \"0\").bn1(avg_pool2d_1)\n",
      "    dense3_0_conv1 = getattr(self.dense3, \"0\").conv1(dense3_0_bn1);  dense3_0_bn1 = None\n",
      "    dense3_0_conv2 = getattr(self.dense3, \"0\").conv2(dense3_0_conv1);  dense3_0_conv1 = None\n",
      "    cat_18 = torch.cat([dense3_0_conv2, avg_pool2d_1], 1);  dense3_0_conv2 = avg_pool2d_1 = None\n",
      "    dense3_1_bn1 = getattr(self.dense3, \"1\").bn1(cat_18)\n",
      "    dense3_1_conv1 = getattr(self.dense3, \"1\").conv1(dense3_1_bn1);  dense3_1_bn1 = None\n",
      "    dense3_1_conv2 = getattr(self.dense3, \"1\").conv2(dense3_1_conv1);  dense3_1_conv1 = None\n",
      "    cat_19 = torch.cat([dense3_1_conv2, cat_18], 1);  dense3_1_conv2 = cat_18 = None\n",
      "    dense3_2_bn1 = getattr(self.dense3, \"2\").bn1(cat_19)\n",
      "    dense3_2_conv1 = getattr(self.dense3, \"2\").conv1(dense3_2_bn1);  dense3_2_bn1 = None\n",
      "    dense3_2_conv2 = getattr(self.dense3, \"2\").conv2(dense3_2_conv1);  dense3_2_conv1 = None\n",
      "    cat_20 = torch.cat([dense3_2_conv2, cat_19], 1);  dense3_2_conv2 = cat_19 = None\n",
      "    dense3_3_bn1 = getattr(self.dense3, \"3\").bn1(cat_20)\n",
      "    dense3_3_conv1 = getattr(self.dense3, \"3\").conv1(dense3_3_bn1);  dense3_3_bn1 = None\n",
      "    dense3_3_conv2 = getattr(self.dense3, \"3\").conv2(dense3_3_conv1);  dense3_3_conv1 = None\n",
      "    cat_21 = torch.cat([dense3_3_conv2, cat_20], 1);  dense3_3_conv2 = cat_20 = None\n",
      "    dense3_4_bn1 = getattr(self.dense3, \"4\").bn1(cat_21)\n",
      "    dense3_4_conv1 = getattr(self.dense3, \"4\").conv1(dense3_4_bn1);  dense3_4_bn1 = None\n",
      "    dense3_4_conv2 = getattr(self.dense3, \"4\").conv2(dense3_4_conv1);  dense3_4_conv1 = None\n",
      "    cat_22 = torch.cat([dense3_4_conv2, cat_21], 1);  dense3_4_conv2 = cat_21 = None\n",
      "    dense3_5_bn1 = getattr(self.dense3, \"5\").bn1(cat_22)\n",
      "    dense3_5_conv1 = getattr(self.dense3, \"5\").conv1(dense3_5_bn1);  dense3_5_bn1 = None\n",
      "    dense3_5_conv2 = getattr(self.dense3, \"5\").conv2(dense3_5_conv1);  dense3_5_conv1 = None\n",
      "    cat_23 = torch.cat([dense3_5_conv2, cat_22], 1);  dense3_5_conv2 = cat_22 = None\n",
      "    dense3_6_bn1 = getattr(self.dense3, \"6\").bn1(cat_23)\n",
      "    dense3_6_conv1 = getattr(self.dense3, \"6\").conv1(dense3_6_bn1);  dense3_6_bn1 = None\n",
      "    dense3_6_conv2 = getattr(self.dense3, \"6\").conv2(dense3_6_conv1);  dense3_6_conv1 = None\n",
      "    cat_24 = torch.cat([dense3_6_conv2, cat_23], 1);  dense3_6_conv2 = cat_23 = None\n",
      "    dense3_7_bn1 = getattr(self.dense3, \"7\").bn1(cat_24)\n",
      "    dense3_7_conv1 = getattr(self.dense3, \"7\").conv1(dense3_7_bn1);  dense3_7_bn1 = None\n",
      "    dense3_7_conv2 = getattr(self.dense3, \"7\").conv2(dense3_7_conv1);  dense3_7_conv1 = None\n",
      "    cat_25 = torch.cat([dense3_7_conv2, cat_24], 1);  dense3_7_conv2 = cat_24 = None\n",
      "    dense3_8_bn1 = getattr(self.dense3, \"8\").bn1(cat_25)\n",
      "    dense3_8_conv1 = getattr(self.dense3, \"8\").conv1(dense3_8_bn1);  dense3_8_bn1 = None\n",
      "    dense3_8_conv2 = getattr(self.dense3, \"8\").conv2(dense3_8_conv1);  dense3_8_conv1 = None\n",
      "    cat_26 = torch.cat([dense3_8_conv2, cat_25], 1);  dense3_8_conv2 = cat_25 = None\n",
      "    dense3_9_bn1 = getattr(self.dense3, \"9\").bn1(cat_26)\n",
      "    dense3_9_conv1 = getattr(self.dense3, \"9\").conv1(dense3_9_bn1);  dense3_9_bn1 = None\n",
      "    dense3_9_conv2 = getattr(self.dense3, \"9\").conv2(dense3_9_conv1);  dense3_9_conv1 = None\n",
      "    cat_27 = torch.cat([dense3_9_conv2, cat_26], 1);  dense3_9_conv2 = cat_26 = None\n",
      "    dense3_10_bn1 = getattr(self.dense3, \"10\").bn1(cat_27)\n",
      "    dense3_10_conv1 = getattr(self.dense3, \"10\").conv1(dense3_10_bn1);  dense3_10_bn1 = None\n",
      "    dense3_10_conv2 = getattr(self.dense3, \"10\").conv2(dense3_10_conv1);  dense3_10_conv1 = None\n",
      "    cat_28 = torch.cat([dense3_10_conv2, cat_27], 1);  dense3_10_conv2 = cat_27 = None\n",
      "    dense3_11_bn1 = getattr(self.dense3, \"11\").bn1(cat_28)\n",
      "    dense3_11_conv1 = getattr(self.dense3, \"11\").conv1(dense3_11_bn1);  dense3_11_bn1 = None\n",
      "    dense3_11_conv2 = getattr(self.dense3, \"11\").conv2(dense3_11_conv1);  dense3_11_conv1 = None\n",
      "    cat_29 = torch.cat([dense3_11_conv2, cat_28], 1);  dense3_11_conv2 = cat_28 = None\n",
      "    dense3_12_bn1 = getattr(self.dense3, \"12\").bn1(cat_29)\n",
      "    dense3_12_conv1 = getattr(self.dense3, \"12\").conv1(dense3_12_bn1);  dense3_12_bn1 = None\n",
      "    dense3_12_conv2 = getattr(self.dense3, \"12\").conv2(dense3_12_conv1);  dense3_12_conv1 = None\n",
      "    cat_30 = torch.cat([dense3_12_conv2, cat_29], 1);  dense3_12_conv2 = cat_29 = None\n",
      "    dense3_13_bn1 = getattr(self.dense3, \"13\").bn1(cat_30)\n",
      "    dense3_13_conv1 = getattr(self.dense3, \"13\").conv1(dense3_13_bn1);  dense3_13_bn1 = None\n",
      "    dense3_13_conv2 = getattr(self.dense3, \"13\").conv2(dense3_13_conv1);  dense3_13_conv1 = None\n",
      "    cat_31 = torch.cat([dense3_13_conv2, cat_30], 1);  dense3_13_conv2 = cat_30 = None\n",
      "    dense3_14_bn1 = getattr(self.dense3, \"14\").bn1(cat_31)\n",
      "    dense3_14_conv1 = getattr(self.dense3, \"14\").conv1(dense3_14_bn1);  dense3_14_bn1 = None\n",
      "    dense3_14_conv2 = getattr(self.dense3, \"14\").conv2(dense3_14_conv1);  dense3_14_conv1 = None\n",
      "    cat_32 = torch.cat([dense3_14_conv2, cat_31], 1);  dense3_14_conv2 = cat_31 = None\n",
      "    dense3_15_bn1 = getattr(self.dense3, \"15\").bn1(cat_32)\n",
      "    dense3_15_conv1 = getattr(self.dense3, \"15\").conv1(dense3_15_bn1);  dense3_15_bn1 = None\n",
      "    dense3_15_conv2 = getattr(self.dense3, \"15\").conv2(dense3_15_conv1);  dense3_15_conv1 = None\n",
      "    cat_33 = torch.cat([dense3_15_conv2, cat_32], 1);  dense3_15_conv2 = cat_32 = None\n",
      "    dense3_16_bn1 = getattr(self.dense3, \"16\").bn1(cat_33)\n",
      "    dense3_16_conv1 = getattr(self.dense3, \"16\").conv1(dense3_16_bn1);  dense3_16_bn1 = None\n",
      "    dense3_16_conv2 = getattr(self.dense3, \"16\").conv2(dense3_16_conv1);  dense3_16_conv1 = None\n",
      "    cat_34 = torch.cat([dense3_16_conv2, cat_33], 1);  dense3_16_conv2 = cat_33 = None\n",
      "    dense3_17_bn1 = getattr(self.dense3, \"17\").bn1(cat_34)\n",
      "    dense3_17_conv1 = getattr(self.dense3, \"17\").conv1(dense3_17_bn1);  dense3_17_bn1 = None\n",
      "    dense3_17_conv2 = getattr(self.dense3, \"17\").conv2(dense3_17_conv1);  dense3_17_conv1 = None\n",
      "    cat_35 = torch.cat([dense3_17_conv2, cat_34], 1);  dense3_17_conv2 = cat_34 = None\n",
      "    dense3_18_bn1 = getattr(self.dense3, \"18\").bn1(cat_35)\n",
      "    dense3_18_conv1 = getattr(self.dense3, \"18\").conv1(dense3_18_bn1);  dense3_18_bn1 = None\n",
      "    dense3_18_conv2 = getattr(self.dense3, \"18\").conv2(dense3_18_conv1);  dense3_18_conv1 = None\n",
      "    cat_36 = torch.cat([dense3_18_conv2, cat_35], 1);  dense3_18_conv2 = cat_35 = None\n",
      "    dense3_19_bn1 = getattr(self.dense3, \"19\").bn1(cat_36)\n",
      "    dense3_19_conv1 = getattr(self.dense3, \"19\").conv1(dense3_19_bn1);  dense3_19_bn1 = None\n",
      "    dense3_19_conv2 = getattr(self.dense3, \"19\").conv2(dense3_19_conv1);  dense3_19_conv1 = None\n",
      "    cat_37 = torch.cat([dense3_19_conv2, cat_36], 1);  dense3_19_conv2 = cat_36 = None\n",
      "    dense3_20_bn1 = getattr(self.dense3, \"20\").bn1(cat_37)\n",
      "    dense3_20_conv1 = getattr(self.dense3, \"20\").conv1(dense3_20_bn1);  dense3_20_bn1 = None\n",
      "    dense3_20_conv2 = getattr(self.dense3, \"20\").conv2(dense3_20_conv1);  dense3_20_conv1 = None\n",
      "    cat_38 = torch.cat([dense3_20_conv2, cat_37], 1);  dense3_20_conv2 = cat_37 = None\n",
      "    dense3_21_bn1 = getattr(self.dense3, \"21\").bn1(cat_38)\n",
      "    dense3_21_conv1 = getattr(self.dense3, \"21\").conv1(dense3_21_bn1);  dense3_21_bn1 = None\n",
      "    dense3_21_conv2 = getattr(self.dense3, \"21\").conv2(dense3_21_conv1);  dense3_21_conv1 = None\n",
      "    cat_39 = torch.cat([dense3_21_conv2, cat_38], 1);  dense3_21_conv2 = cat_38 = None\n",
      "    dense3_22_bn1 = getattr(self.dense3, \"22\").bn1(cat_39)\n",
      "    dense3_22_conv1 = getattr(self.dense3, \"22\").conv1(dense3_22_bn1);  dense3_22_bn1 = None\n",
      "    dense3_22_conv2 = getattr(self.dense3, \"22\").conv2(dense3_22_conv1);  dense3_22_conv1 = None\n",
      "    cat_40 = torch.cat([dense3_22_conv2, cat_39], 1);  dense3_22_conv2 = cat_39 = None\n",
      "    dense3_23_bn1 = getattr(self.dense3, \"23\").bn1(cat_40)\n",
      "    dense3_23_conv1 = getattr(self.dense3, \"23\").conv1(dense3_23_bn1);  dense3_23_bn1 = None\n",
      "    dense3_23_conv2 = getattr(self.dense3, \"23\").conv2(dense3_23_conv1);  dense3_23_conv1 = None\n",
      "    cat_41 = torch.cat([dense3_23_conv2, cat_40], 1);  dense3_23_conv2 = cat_40 = None\n",
      "    trans3_bn = self.trans3.bn(cat_41);  cat_41 = None\n",
      "    trans3_conv = self.trans3.conv(trans3_bn);  trans3_bn = None\n",
      "    avg_pool2d_2 = torch._C._nn.avg_pool2d(trans3_conv, 2);  trans3_conv = None\n",
      "    dense4_0_bn1 = getattr(self.dense4, \"0\").bn1(avg_pool2d_2)\n",
      "    dense4_0_conv1 = getattr(self.dense4, \"0\").conv1(dense4_0_bn1);  dense4_0_bn1 = None\n",
      "    dense4_0_conv2 = getattr(self.dense4, \"0\").conv2(dense4_0_conv1);  dense4_0_conv1 = None\n",
      "    cat_42 = torch.cat([dense4_0_conv2, avg_pool2d_2], 1);  dense4_0_conv2 = avg_pool2d_2 = None\n",
      "    dense4_1_bn1 = getattr(self.dense4, \"1\").bn1(cat_42)\n",
      "    dense4_1_conv1 = getattr(self.dense4, \"1\").conv1(dense4_1_bn1);  dense4_1_bn1 = None\n",
      "    dense4_1_conv2 = getattr(self.dense4, \"1\").conv2(dense4_1_conv1);  dense4_1_conv1 = None\n",
      "    cat_43 = torch.cat([dense4_1_conv2, cat_42], 1);  dense4_1_conv2 = cat_42 = None\n",
      "    dense4_2_bn1 = getattr(self.dense4, \"2\").bn1(cat_43)\n",
      "    dense4_2_conv1 = getattr(self.dense4, \"2\").conv1(dense4_2_bn1);  dense4_2_bn1 = None\n",
      "    dense4_2_conv2 = getattr(self.dense4, \"2\").conv2(dense4_2_conv1);  dense4_2_conv1 = None\n",
      "    cat_44 = torch.cat([dense4_2_conv2, cat_43], 1);  dense4_2_conv2 = cat_43 = None\n",
      "    dense4_3_bn1 = getattr(self.dense4, \"3\").bn1(cat_44)\n",
      "    dense4_3_conv1 = getattr(self.dense4, \"3\").conv1(dense4_3_bn1);  dense4_3_bn1 = None\n",
      "    dense4_3_conv2 = getattr(self.dense4, \"3\").conv2(dense4_3_conv1);  dense4_3_conv1 = None\n",
      "    cat_45 = torch.cat([dense4_3_conv2, cat_44], 1);  dense4_3_conv2 = cat_44 = None\n",
      "    dense4_4_bn1 = getattr(self.dense4, \"4\").bn1(cat_45)\n",
      "    dense4_4_conv1 = getattr(self.dense4, \"4\").conv1(dense4_4_bn1);  dense4_4_bn1 = None\n",
      "    dense4_4_conv2 = getattr(self.dense4, \"4\").conv2(dense4_4_conv1);  dense4_4_conv1 = None\n",
      "    cat_46 = torch.cat([dense4_4_conv2, cat_45], 1);  dense4_4_conv2 = cat_45 = None\n",
      "    dense4_5_bn1 = getattr(self.dense4, \"5\").bn1(cat_46)\n",
      "    dense4_5_conv1 = getattr(self.dense4, \"5\").conv1(dense4_5_bn1);  dense4_5_bn1 = None\n",
      "    dense4_5_conv2 = getattr(self.dense4, \"5\").conv2(dense4_5_conv1);  dense4_5_conv1 = None\n",
      "    cat_47 = torch.cat([dense4_5_conv2, cat_46], 1);  dense4_5_conv2 = cat_46 = None\n",
      "    dense4_6_bn1 = getattr(self.dense4, \"6\").bn1(cat_47)\n",
      "    dense4_6_conv1 = getattr(self.dense4, \"6\").conv1(dense4_6_bn1);  dense4_6_bn1 = None\n",
      "    dense4_6_conv2 = getattr(self.dense4, \"6\").conv2(dense4_6_conv1);  dense4_6_conv1 = None\n",
      "    cat_48 = torch.cat([dense4_6_conv2, cat_47], 1);  dense4_6_conv2 = cat_47 = None\n",
      "    dense4_7_bn1 = getattr(self.dense4, \"7\").bn1(cat_48)\n",
      "    dense4_7_conv1 = getattr(self.dense4, \"7\").conv1(dense4_7_bn1);  dense4_7_bn1 = None\n",
      "    dense4_7_conv2 = getattr(self.dense4, \"7\").conv2(dense4_7_conv1);  dense4_7_conv1 = None\n",
      "    cat_49 = torch.cat([dense4_7_conv2, cat_48], 1);  dense4_7_conv2 = cat_48 = None\n",
      "    dense4_8_bn1 = getattr(self.dense4, \"8\").bn1(cat_49)\n",
      "    dense4_8_conv1 = getattr(self.dense4, \"8\").conv1(dense4_8_bn1);  dense4_8_bn1 = None\n",
      "    dense4_8_conv2 = getattr(self.dense4, \"8\").conv2(dense4_8_conv1);  dense4_8_conv1 = None\n",
      "    cat_50 = torch.cat([dense4_8_conv2, cat_49], 1);  dense4_8_conv2 = cat_49 = None\n",
      "    dense4_9_bn1 = getattr(self.dense4, \"9\").bn1(cat_50)\n",
      "    dense4_9_conv1 = getattr(self.dense4, \"9\").conv1(dense4_9_bn1);  dense4_9_bn1 = None\n",
      "    dense4_9_conv2 = getattr(self.dense4, \"9\").conv2(dense4_9_conv1);  dense4_9_conv1 = None\n",
      "    cat_51 = torch.cat([dense4_9_conv2, cat_50], 1);  dense4_9_conv2 = cat_50 = None\n",
      "    dense4_10_bn1 = getattr(self.dense4, \"10\").bn1(cat_51)\n",
      "    dense4_10_conv1 = getattr(self.dense4, \"10\").conv1(dense4_10_bn1);  dense4_10_bn1 = None\n",
      "    dense4_10_conv2 = getattr(self.dense4, \"10\").conv2(dense4_10_conv1);  dense4_10_conv1 = None\n",
      "    cat_52 = torch.cat([dense4_10_conv2, cat_51], 1);  dense4_10_conv2 = cat_51 = None\n",
      "    dense4_11_bn1 = getattr(self.dense4, \"11\").bn1(cat_52)\n",
      "    dense4_11_conv1 = getattr(self.dense4, \"11\").conv1(dense4_11_bn1);  dense4_11_bn1 = None\n",
      "    dense4_11_conv2 = getattr(self.dense4, \"11\").conv2(dense4_11_conv1);  dense4_11_conv1 = None\n",
      "    cat_53 = torch.cat([dense4_11_conv2, cat_52], 1);  dense4_11_conv2 = cat_52 = None\n",
      "    dense4_12_bn1 = getattr(self.dense4, \"12\").bn1(cat_53)\n",
      "    dense4_12_conv1 = getattr(self.dense4, \"12\").conv1(dense4_12_bn1);  dense4_12_bn1 = None\n",
      "    dense4_12_conv2 = getattr(self.dense4, \"12\").conv2(dense4_12_conv1);  dense4_12_conv1 = None\n",
      "    cat_54 = torch.cat([dense4_12_conv2, cat_53], 1);  dense4_12_conv2 = cat_53 = None\n",
      "    dense4_13_bn1 = getattr(self.dense4, \"13\").bn1(cat_54)\n",
      "    dense4_13_conv1 = getattr(self.dense4, \"13\").conv1(dense4_13_bn1);  dense4_13_bn1 = None\n",
      "    dense4_13_conv2 = getattr(self.dense4, \"13\").conv2(dense4_13_conv1);  dense4_13_conv1 = None\n",
      "    cat_55 = torch.cat([dense4_13_conv2, cat_54], 1);  dense4_13_conv2 = cat_54 = None\n",
      "    dense4_14_bn1 = getattr(self.dense4, \"14\").bn1(cat_55)\n",
      "    dense4_14_conv1 = getattr(self.dense4, \"14\").conv1(dense4_14_bn1);  dense4_14_bn1 = None\n",
      "    dense4_14_conv2 = getattr(self.dense4, \"14\").conv2(dense4_14_conv1);  dense4_14_conv1 = None\n",
      "    cat_56 = torch.cat([dense4_14_conv2, cat_55], 1);  dense4_14_conv2 = cat_55 = None\n",
      "    dense4_15_bn1 = getattr(self.dense4, \"15\").bn1(cat_56)\n",
      "    dense4_15_conv1 = getattr(self.dense4, \"15\").conv1(dense4_15_bn1);  dense4_15_bn1 = None\n",
      "    dense4_15_conv2 = getattr(self.dense4, \"15\").conv2(dense4_15_conv1);  dense4_15_conv1 = None\n",
      "    cat_57 = torch.cat([dense4_15_conv2, cat_56], 1);  dense4_15_conv2 = cat_56 = None\n",
      "    bn = self.bn(cat_57);  cat_57 = None\n",
      "    avg_pool2d_3 = torch._C._nn.avg_pool2d(bn, 4);  bn = None\n",
      "    size = avg_pool2d_3.size(0)\n",
      "    view = avg_pool2d_3.view(size, -1);  avg_pool2d_3 = size = None\n",
      "    linear = self.linear(view);  view = None\n",
      "    dequantize_246 = linear.dequantize();  linear = None\n",
      "    return dequantize_246\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "example_inputs = (next(iter(train_loader))[0],)\n",
    "prepared_model = prepare_fx(model, qconfig_dict, example_inputs)\n",
    "quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "print(quantized_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27b3dfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 7.89627\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a419d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "for m in model.modules():\n",
    "    if isinstance(m, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        m.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        torch.quantization.prepare(m, inplace=True)\n",
    "        torch.quantization.convert(m, inplace=True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a3aeef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (dense1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans1): Transition(\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans2): Transition(\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans3): Transition(\n",
      "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62ba7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "483ad031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 28.353676\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f10c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834fdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3e08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(test_loader, model, criterion, \"cuda\", half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c032e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mymodelbc = BC(model)\n",
    "optimiser = optim.SGD(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda\"\n",
    "\n",
    "train_loader = get_train_cifar10(transform_test, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c65ce25",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m optimiser.step()\n\u001b[32m     19\u001b[39m mymodelbc.clip()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m total += targets.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "best_acc = 0\n",
    "start_epoch = 0\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+n_epochs):\n",
    "    mymodelbc.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        outputs = mymodelbc(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        mymodelbc.clip()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "372910f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train\n",
    "\n",
    "\n",
    "def quantise_aware_train(\n",
    "        train_loader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimiser: \"Optimizer\",\n",
    "        criterion,\n",
    "        qconfig: str = \"fbgemm\",\n",
    "        device: str = \"cuda\",\n",
    "        n_epochs: int = 500,\n",
    "    ) -> None:\n",
    "    model.qconfig = torch.quantization.get_default_qat_qconfig(qconfig)\n",
    "    torch.quantization.prepare_qat(model, inplace=True)\n",
    "    \n",
    "    for _ in range(n_epochs):\n",
    "        acc, loss = train(\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimiser,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "    model = model.to('cpu')\n",
    "    torch.quantization.convert(model, inplace=True)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e171d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as transformsv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73ef6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_cifar10_train_val_loaders, ROOT_DIR, DEFAULT_TRANSFORM, print_size_of_model, subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.579704\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported qscheme: per_channel_affine",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m         optimizer.step()\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Convert to quantized model after training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Now, the model is quantized and can be used for inference.\u001b[39;00m\n\u001b[32m     64\u001b[39m print_size_of_model(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:657\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[32m    656\u001b[39m     module = copy.deepcopy(module)\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remove_qconfig:\n\u001b[32m    666\u001b[39m     _remove_qconfig(module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:722\u001b[39m, in \u001b[36m_convert\u001b[39m\u001b[34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule)\n\u001b[32m    712\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping\n\u001b[32m    713\u001b[39m     ):\n\u001b[32m    714\u001b[39m         _convert(\n\u001b[32m    715\u001b[39m             mod,\n\u001b[32m    716\u001b[39m             mapping,\n\u001b[32m   (...)\u001b[39m\u001b[32m    720\u001b[39m             use_precomputed_fake_quant=use_precomputed_fake_quant,\n\u001b[32m    721\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     reassign[name] = \u001b[43mswap_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_module_class_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign.items():\n\u001b[32m    727\u001b[39m     module._modules[key] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:764\u001b[39m, in \u001b[36mswap_module\u001b[39m\u001b[34m(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    762\u001b[39m sig = inspect.signature(qmod.from_float)\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_precomputed_fake_quant\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sig.parameters:\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     new_mod = \u001b[43mqmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    768\u001b[39m     new_mod = qmod.from_float(mod)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:606\u001b[39m, in \u001b[36mConv2d.from_float\u001b[39m\u001b[34m(cls, mod, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_float\u001b[39m(\u001b[38;5;28mcls\u001b[39m, mod, use_precomputed_fake_quant=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    600\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001b[39;00m\n\u001b[32m    601\u001b[39m \n\u001b[32m    602\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[33;03m        mod (Module): a float module, either produced by torch.ao.quantization\u001b[39;00m\n\u001b[32m    604\u001b[39m \u001b[33;03m          utilities or provided by the user\u001b[39;00m\n\u001b[32m    605\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConvNd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:322\u001b[39m, in \u001b[36m_ConvNd.from_float\u001b[39m\u001b[34m(cls, mod, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    320\u001b[39m         mod = mod[\u001b[32m0\u001b[39m]\n\u001b[32m    321\u001b[39m     weight_post_process = mod.qconfig.weight()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_qconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_post_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_post_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:266\u001b[39m, in \u001b[36m_ConvNd.get_qconv\u001b[39m\u001b[34m(cls, mod, activation_post_process, weight_post_process)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[39;00m\n\u001b[32m    255\u001b[39m qconv = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    256\u001b[39m     mod.in_channels,\n\u001b[32m    257\u001b[39m     mod.out_channels,\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m     mod.padding_mode,\n\u001b[32m    265\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mqconv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_weight_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    268\u001b[39m     activation_post_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m activation_post_process.dtype == torch.float\n\u001b[32m    270\u001b[39m ):\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m qconv  \u001b[38;5;66;03m# dynamic quantization doesn't need scale/zero_point\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:567\u001b[39m, in \u001b[36mConv2d.set_weight_bias\u001b[39m\u001b[34m(self, w, b)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_weight_bias\u001b[39m(\u001b[38;5;28mself\u001b[39m, w: torch.Tensor, b: Optional[torch.Tensor]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode == \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m         \u001b[38;5;28mself\u001b[39m._packed_params = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantized\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d_prepack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m            \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    571\u001b[39m         \u001b[38;5;28mself\u001b[39m._packed_params = torch.ops.quantized.conv2d_prepack(\n\u001b[32m    572\u001b[39m             w, b, \u001b[38;5;28mself\u001b[39m.stride, _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    573\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/_ops.py:1123\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsupported qscheme: per_channel_affine"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "train_loader, val_loader = get_cifar10_train_val_loaders(subset=True, num_subset=5000)\n",
    "\n",
    "\n",
    "# Download CIFAR-10 dataset (train and test)\n",
    "train_dataset = subset_data(CIFAR10(root=ROOT_DIR, train=True, download=True, transform=DEFAULT_TRANSFORM), 5000)\n",
    "test_dataset = CIFAR10(root=ROOT_DIR, train=False, download=True, transform=DEFAULT_TRANSFORM)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# Define a simple model (e.g., for QAT)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 30 * 30, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, move to CUDA\n",
    "model = SimpleModel().to('cuda')\n",
    "\n",
    "print_size_of_model(model)\n",
    "\n",
    "\n",
    "\n",
    "# Now, the model is quantized and can be used for inference.\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e895a536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (conv1): QuantizedConv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.06295403838157654, zero_point=63)\n",
       "  (fc1): QuantizedLinear(in_features=14400, out_features=10, scale=0.1440950483083725, zero_point=59, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to('cpu')  # Move the model back to CPU for conversion\n",
    "torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd1d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.148866\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdc0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f388ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.148866\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
