{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062b681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from models import DenseNet121\n",
    "\n",
    "from numpy import linspace\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4a783",
   "metadata": {},
   "source": [
    "### ALL COMMMENTS WITH '##' ARE MINE AND NOT CHAT GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc8d3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_macs(model, input_size=(1, 3, 32, 32), device: str = \"cuda\", half: bool = False):\n",
    "    macs = 0\n",
    "    dummy_input = torch.randn(*input_size).to(device)\n",
    "\n",
    "    def conv_hook(module, input, output):\n",
    "        nonlocal macs\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            batch_size, out_channels, out_h, out_w = output.shape\n",
    "            in_channels, _, kernel_h, kernel_w = module.weight.shape\n",
    "\n",
    "            layer_macs = out_h * out_w * out_channels * kernel_h * kernel_w * in_channels\n",
    "            macs += layer_macs\n",
    "\n",
    "    def linear_hook(module, input, output):\n",
    "        nonlocal macs\n",
    "        if isinstance(module, nn.Linear):\n",
    "            in_features, out_features = module.weight.shape\n",
    "            layer_macs = in_features * out_features\n",
    "            macs += layer_macs\n",
    "\n",
    "    hooks = []\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "            hook = layer.register_forward_hook(conv_hook if isinstance(layer, nn.Conv2d) else linear_hook)\n",
    "            hooks.append(hook)\n",
    "\n",
    "    if half:\n",
    "        dummy_input = dummy_input.half()\n",
    "    model(dummy_input)\n",
    "\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    return macs\n",
    "\n",
    "def calculate_score(p_s, p_u, q_w, q_a, w, f, param_ref, ops_ref):\n",
    "    param_score = ((1 - (p_s + p_u)) * (q_w / 32) * w) / param_ref\n",
    "    ops_score = ((1 - p_s) * (max(q_w, q_a) / 32) * f) / ops_ref\n",
    "    return param_score + ops_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0a4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_train_cifar10_dataloader, get_test_cifar10_dataloader, run_epochs, get_hyperparams, test\n",
    "\n",
    "trainloader = get_train_cifar10_dataloader()\n",
    "testloader = get_test_cifar10_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29ec2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_trained_model, count_nonzero_parameters, run_global_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f61a5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, og_acc = load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e3dc57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ref = count_nonzero_parameters(model)\n",
    "ops_ref = get_macs(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a45b8d",
   "metadata": {},
   "source": [
    "## Global Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d23ac969",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_amounts = linspace(0.1, 1, 10)\n",
    "no_quant_glob_prun_scores = []\n",
    "for amount in prune_amounts[:-1]:\n",
    "    pruning_model = deepcopy(model)\n",
    "    n_params, acc = run_global_pruning(pruning_model, testloader, amount)\n",
    "    score = calculate_score(\n",
    "        0, 1 - (n_params / params_ref), 32, 32, n_params, get_macs(pruning_model), params_ref, ops_ref\n",
    "    )\n",
    "    no_quant_glob_prun_scores.append((score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f93e5608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.8121627983238828, 90.38),\n",
       " (1.643848178818579, 90.4),\n",
       " (1.4950563437762647, 90.13),\n",
       " (1.3657868602068894, 88.96),\n",
       " (1.2560399588083273, 81.44),\n",
       " (1.1658156395805779, 30.66),\n",
       " (1.0951139025236416, 15.49),\n",
       " (1.0439348079012516, 11.89),\n",
       " (1.012278206780244, 10.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_quant_glob_prun_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e28af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce6b9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import global_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5147fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, _ = test(testloader, model, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73a4c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pruning(model, amount=0.1)\n",
    "acc, _ = test(testloader, model, half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f1e9632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6956297"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nonzero_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69acce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_quant_glob_prun_res = []\n",
    "for amount in prune_amounts[:-1]:\n",
    "    unpruned = deepcopy(model)\n",
    "    n_params, acc = run_global_pruning(unpruned, testloader, amount, half=True)\n",
    "    score = calculate_score(\n",
    "        0, 1 - (n_params / params_ref), 16, 16, n_params, get_macs(model, half=True), params_ref, ops_ref\n",
    "    )\n",
    "    half_quant_glob_prun_res.append((score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_quant_glob_prun = {\n",
    "    \"no_quant_glob_prun\": no_quant_glob_prun_scores\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d6b337e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_quant_glob_prun': ((0.05663008744762134, 89.0),\n",
       "  (0.051370255588080595, 89.08),\n",
       "  (0.04672051074300827, 88.48),\n",
       "  (0.042680839381465295, 87.42),\n",
       "  (0.03925124871276023, 80.11),\n",
       "  (0.03643173873689306, 35.64),\n",
       "  (0.0342223094538638, 15.38),\n",
       "  (0.03262296274691411, 12.42),\n",
       "  (0.03163369396188263, 11.34),\n",
       "  (0.0625, 90.44))}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_quant_glob_prun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b94eb553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05663008744762134, 41.4),\n",
       " (0.051370255588080595, 36.87),\n",
       " (0.04672051074300827, 30.81),\n",
       " (0.042680839381465295, 29.5),\n",
       " (0.03925124871276023, 21.53),\n",
       " (0.03643173873689306, 15.89),\n",
       " (0.0342223094538638, 16.35),\n",
       " (0.03262296274691411, 10.66),\n",
       " (0.03163369396188263, 10.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_quant_glob_prun_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cd38edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f38c0e0f650>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [r[0] for r in res]\n",
    "y = [r[1] for r in res]\n",
    "plt.scatter([*prune_amounts[:-1], 0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d3ecb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def zero_out_pruned_filters(model, prune_ratio):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):  \n",
    "            weight = module.weight.data\n",
    "            if weight is None:\n",
    "                continue\n",
    "\n",
    "            if hasattr(module, '_pruned_filters'):\n",
    "                pruned_filters = module._pruned_filters\n",
    "            else:\n",
    "                pruned_filters = []\n",
    "\n",
    "            remaining_filters = set(range(weight.shape[0])) - set(pruned_filters)\n",
    "            if not remaining_filters:\n",
    "                continue\n",
    "            remaining_filters = list(remaining_filters)\n",
    "            filter_norms = weight[remaining_filters].abs().sum(dim=(1, 2, 3) if isinstance(module, nn.Conv2d) else (1,))\n",
    "\n",
    "            _, sorted_indices = torch.sort(filter_norms)\n",
    "\n",
    "            num_filters_to_prune = int(prune_ratio * len(remaining_filters))\n",
    "\n",
    "            filters_to_zero = sorted_indices[:num_filters_to_prune]\n",
    "            filters_to_zero = [remaining_filters[idx] for idx in filters_to_zero]\n",
    "            weight[filters_to_zero] = 0\n",
    "            module._pruned_filters = pruned_filters + filters_to_zero\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 100.\n",
    "n_epochs = 30\n",
    "prune_ratios = [0.2, 0.3, 0.4]\n",
    "\n",
    "train_transforms = get_best_transformations()\n",
    "train_loader, val_loader = get_cifar10_train_val_loaders(transform=train_transforms)\n",
    "test_loader = get_test_cifar10_dataloader()\n",
    "\n",
    "model, _ = load_trained_model()\n",
    "train_details = load_untrained_model(\"DenseNet121\")\n",
    "\n",
    "res = {}\n",
    "for prune_ratio in prune_ratios:\n",
    "\n",
    "    pruning_model = deepcopy(model)\n",
    "\n",
    "    prune_track = []\n",
    "\n",
    "    while acc > 85:\n",
    "        pruning_model = zero_out_pruned_filters(pruning_model, prune_ratio=prune_ratio)\n",
    "        params = count_nonzero_parameters(model)\n",
    "\n",
    "        _, _, _ = run_epochs(\n",
    "            pruning_model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            train_details,\n",
    "            n_epochs=n_epochs,\n",
    "        )\n",
    "\n",
    "        acc, _ = test(\n",
    "            test_loader,\n",
    "            pruning_model,\n",
    "        )\n",
    "\n",
    "        prune_track.append(\n",
    "            (params, acc)\n",
    "        )\n",
    "\n",
    "    res[prune_ratio] = prune_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3525e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e856b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613590"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55699de",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Zero out 30% of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d6273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ad2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim\n",
    "from models import VGG\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Pruning Methods ===\n",
    "\n",
    "# 1. Global Pruning, no retrain\n",
    "## CAUE - There is nothing special here, just applying the pruning function to the model\n",
    "\n",
    "\n",
    "# 2. Global Pruning + Retrain\n",
    "## CAUE - The same as the previous one, but retraining the model after the pruning\n",
    "def method2_global_pruning_with_retrain(model, trainloader, testloader):\n",
    "    print(\"\\n=== Method 2: Global Pruning with Retrain ===\")\n",
    "\n",
    "    apply_global_pruning(model, amount=0.3)\n",
    "\n",
    "    acc, _, _ = run_epochs(\n",
    "        model,\n",
    "        train_loader=trainloader,\n",
    "        test_loader=testloader,\n",
    "        hyperparams=HYPERPARAMS,\n",
    "        n_epochs=1,\n",
    "    )\n",
    "\n",
    "    params = count_nonzero_parameters(model)\n",
    "    print(f\"Accuracy after retrain: {acc:.2f}% | Parameters: {params}\")\n",
    "\n",
    "    remove_pruning(model)\n",
    "\n",
    "# 3. Gradual Pruning por etapas + Retrain\n",
    "## CAUE - What I understood from this one was that we apply the pruning many times (steps)\n",
    "## It is possible to change the pruning ratio in each step if we want\n",
    "def method3_gradual_pruning(model, trainloader, testloader):\n",
    "    print(\"\\n=== Method 3: Gradual Pruning + Retrain ===\")\n",
    "    \n",
    "    total_steps = 3\n",
    "    pruning_amount_per_step = 0.1\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        print(f\"\\n-- Step {step+1}/{total_steps} --\")\n",
    "        apply_global_pruning(model, amount=pruning_amount_per_step)\n",
    "\n",
    "        acc, _, _ = run_epochs(\n",
    "            model,\n",
    "            train_loader=trainloader,\n",
    "            test_loader=testloader,\n",
    "            hyperparams=HYPERPARAMS,\n",
    "            n_epochs=1, \n",
    "        )\n",
    "\n",
    "        params = count_nonzero_parameters(model)\n",
    "        print(f\"Accuracy: {acc:.2f}% | Parameters: {params}\")\n",
    "\n",
    "    remove_pruning(model)\n",
    "\n",
    "# 4. ThiNet\n",
    "## CAUE - This one I've looked up and I found an article that describes the state of art\n",
    "## The article can be found in here: https://arxiv.org/abs/1707.06342\n",
    "## As far what I've read, it uses the L2 norm to discard the whole filter if it is considered not important\n",
    "## and not the individual weight like how we have been doing\n",
    "def method4_thinet_style_pruning(model, trainloader, testloader):\n",
    "    print(\"\\n=== Method 4: ThiNet Style Pruning ===\")\n",
    "    \n",
    "    def prune_by_feature_map_norm(model, amount=0.3):\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                weight = module.weight.detach()\n",
    "                filter_norms = weight.view(weight.size(0), -1).norm(2, dim=1)\n",
    "                num_filters_to_prune = int(amount * weight.size(0))\n",
    "                prune_idx = filter_norms.argsort()[:num_filters_to_prune]\n",
    "\n",
    "                mask = torch.ones(weight.size(0), device=weight.device)\n",
    "                mask[prune_idx] = 0\n",
    "\n",
    "                mask = mask[:, None, None, None]\n",
    "                module.weight.data.mul_(mask)\n",
    "\n",
    "    prune_by_feature_map_norm(model, amount=0.3)\n",
    "\n",
    "    acc, _, _ = run_epochs(\n",
    "        model,\n",
    "        train_loader=trainloader,\n",
    "        test_loader=testloader,\n",
    "        hyperparams=HYPERPARAMS,\n",
    "        n_epochs=1,\n",
    "    )\n",
    "\n",
    "    params = count_nonzero_parameters(model)\n",
    "    print(f\"Accuracy after ThiNet pruning + retrain: {acc:.2f}% | Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b82b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before pruning: 10.00%\n",
      "\n",
      "=== Method 1: Global Pruning without Retrain ===\n",
      "Accuracy: 10.00% | Parameters: 20035016\n",
      "\n",
      "=== Method 2: Global Pruning with Retrain ===\n",
      "Epoch: 0\n",
      "Saving..\n",
      "Accuracy after retrain: 58.93% | Parameters: 14033322\n",
      "\n",
      "=== Method 3: Gradual Pruning + Retrain ===\n",
      "\n",
      "-- Step 1/3 --\n",
      "Epoch: 0\n",
      "Saving..\n",
      "Accuracy: 71.93% | Parameters: 17954449\n",
      "\n",
      "-- Step 2/3 --\n",
      "Epoch: 0\n",
      "Saving..\n",
      "Accuracy: 74.17% | Parameters: 17954449\n",
      "\n",
      "-- Step 3/3 --\n",
      "Epoch: 0\n",
      "Saving..\n",
      "Accuracy: 80.17% | Parameters: 17954449\n",
      "\n",
      "=== Method 4: ThiNet Style Pruning ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m method2_global_pruning_with_retrain(model, trainloader, testloader)\n\u001b[32m     13\u001b[39m method3_gradual_pruning(model, trainloader, testloader)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mmethod4_thinet_style_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mmethod4_thinet_style_pruning\u001b[39m\u001b[34m(model, trainloader, testloader)\u001b[39m\n\u001b[32m    106\u001b[39m             mask = mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    107\u001b[39m             module.weight.data.mul_(mask)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[43mprune_by_feature_map_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m acc, _, _ = run_epochs(\n\u001b[32m    112\u001b[39m     model,\n\u001b[32m    113\u001b[39m     train_loader=trainloader,\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m     n_epochs=\u001b[32m1\u001b[39m,\n\u001b[32m    117\u001b[39m )\n\u001b[32m    119\u001b[39m params = count_nonzero_parameters(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mmethod4_thinet_style_pruning.<locals>.prune_by_feature_map_norm\u001b[39m\u001b[34m(model, amount)\u001b[39m\n\u001b[32m    104\u001b[39m mask[prune_idx] = \u001b[32m0\u001b[39m\n\u001b[32m    106\u001b[39m mask = mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "model = VGG(\"VGG19\").to(device)\n",
    "trainloader = get_train_cifar10_dataloader()\n",
    "testloader = get_test_cifar10_dataloader()\n",
    "\n",
    "## CAUE - I used your function to get the hyperparameters, but I changed the way the optimiser was defined\n",
    "## because the pickle returns it as a string\n",
    "HYPERPARAMS = get_hyperparams()\n",
    "HYPERPARAMS[\"criterion\"] = nn.CrossEntropyLoss()\n",
    "HYPERPARAMS[\"optimiser\"] = optim.AdamW(model.parameters(), lr=HYPERPARAMS['lr'], weight_decay=HYPERPARAMS['weight_decay'])\n",
    "\n",
    "acc_before, _ = test(testloader, model)\n",
    "print(f\"Accuracy before pruning: {acc_before:.2f}%\")\n",
    "\n",
    "method1_global_pruning_no_retrain(model, trainloader, testloader)\n",
    "method2_global_pruning_with_retrain(model, trainloader, testloader)\n",
    "method3_gradual_pruning(model, trainloader, testloader)\n",
    "#method4_thinet_style_pruning(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38fd98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Method 4: ThiNet Style Pruning ===\n",
      "Epoch: 0\n",
      "Saving..\n",
      "Accuracy after ThiNet pruning + retrain: 79.81% | Parameters: 20019550\n"
     ]
    }
   ],
   "source": [
    "method4_thinet_style_pruning(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25671"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CAUE - At some point I had to use this because I got a OutOfMemoryError when running the models\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
