{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa520c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef7960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b18d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"thinet_prune_half_quant.pkl\", \"rb\") as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8271872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2, 15.26, 1.0), (0.3, 10.02, 1.0), (0.4, 10.0, 1.0), (0.5, 10.0, 1.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459293f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils import (\n",
    "    calculate_score,\n",
    "    count_nonzero_parameters,\n",
    "    get_best_transformations,\n",
    "    get_cifar10_train_val_loaders,\n",
    "    get_device,\n",
    "    get_macs,\n",
    "    get_test_cifar10_dataloader,\n",
    "    load_trained_model,\n",
    "    load_untrained_model,\n",
    "    pickle_dump,\n",
    "    run_epochs,\n",
    "    test,\n",
    ")\n",
    "\n",
    "\n",
    "def collect_outputs(model, layer, calibration_loader, device, half: bool = False):\n",
    "    outputs = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        outputs.append(output.detach().cpu())\n",
    "\n",
    "    handle = layer.register_forward_hook(hook_fn)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in calibration_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            if half:\n",
    "                inputs = inputs.half()\n",
    "            model(inputs)\n",
    "            break\n",
    "    handle.remove()\n",
    "    return outputs[0]\n",
    "\n",
    "def prune_filters_by_zeroing(layer, calibration_outputs, prune_ratio):\n",
    "    num_filters = layer.weight.size(0)\n",
    "    num_prune = int(num_filters * prune_ratio)\n",
    "    importance = calibration_outputs.view(calibration_outputs.size(0), num_filters, -1).norm(2, dim=2).mean(0)\n",
    "    _, prune_idx = torch.topk(importance, num_prune, largest=False)\n",
    "    with torch.no_grad():\n",
    "        layer.weight[prune_idx, :, :, :] = 0\n",
    "        if layer.bias is not None:\n",
    "            layer.bias[prune_idx] = 0\n",
    "    return prune_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be9e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train_transforms = get_best_transformations()\n",
    "train_loader, val_loader = get_cifar10_train_val_loaders(transform=train_transforms)\n",
    "test_loader = get_test_cifar10_dataloader()\n",
    "\n",
    "model, _ = load_trained_model()\n",
    "model.half()\n",
    "params_ref, ops_ref = count_nonzero_parameters(model), get_macs(model, half=True)\n",
    "train_details = load_untrained_model(\"DenseNet121\")\n",
    "device = get_device()\n",
    "\n",
    "calibration_loader = train_loader\n",
    "prune_ratios = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "num_pruning_rounds = 1\n",
    "n_epochs = 20\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d45490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prune_ratio in prune_ratios[:1]:\n",
    "    print(\"Prune ratio: \", prune_ratio)\n",
    "    pruning_model = deepcopy(model)\n",
    "\n",
    "    for pruning_round in range(num_pruning_rounds):\n",
    "        print(\"Prune round: \", pruning_round)\n",
    "        for layer in pruning_model.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                calibration_outputs = collect_outputs(\n",
    "                    pruning_model, layer, calibration_loader, device, half=True,\n",
    "                )\n",
    "                prune_filters_by_zeroing(layer, calibration_outputs, prune_ratio)\n",
    "\n",
    "        _, _, _ = run_epochs(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            train_details,\n",
    "            n_epochs=n_epochs,\n",
    "            half=True,\n",
    "        )\n",
    "    test_acc, _ = test(\n",
    "        test_loader,\n",
    "        pruning_model,\n",
    "        half=True,\n",
    "    )\n",
    "    params = count_nonzero_parameters(pruning_model)\n",
    "\n",
    "    score = calculate_score(\n",
    "        1 - (params / params_ref), 0, 16, 16, params, get_macs(pruning_model, half=True), params_ref, ops_ref\n",
    "    )\n",
    "    res.append(\n",
    "        (prune_ratio, test_acc, score, params)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa157598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a94da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900088a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84161bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe6d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275f044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44654db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for pruning_round in range(num_pruning_rounds):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            calibration_outputs = collect_outputs(model, layer, calibration_loader, device)\n",
    "            prune_filters_by_zeroing(layer, calibration_outputs, prune_ratio)\n",
    "\n",
    "    _, _ = train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        train_details[\"optimiser\"],\n",
    "        train_details[\"criterion\"],\n",
    "        device,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a5d3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2646a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5630118"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nonzero_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6dca256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'scheduler', 'optimiser', 'criterion'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_details.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f69620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e238d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6ad6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d86b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
