{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1aa540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "from binaryconnect import BC\n",
    "from models import DenseNet121\n",
    "from utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0c91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "model = DenseNet121()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd00b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 28.353676\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78329f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486dd32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe493fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = quantise_dynamic(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "401c4faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 28.323778\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d43ca38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ec2d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'models.densenet.DenseNet'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Transition'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Transition'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Transition'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'models.densenet.Bottleneck'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.ao.nn.quantized.dynamic.modules.linear.Linear'>\n",
      "<class 'torch.ao.nn.quantized.modules.linear.LinearPackedParams'>\n"
     ]
    }
   ],
   "source": [
    "for m in quantized_model.modules():\n",
    "    print(type(m))\n",
    "    if isinstance(m, nn.Linear):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_backends = [\"fbgemm\", \"x86\", \"qnnpack\", \"onednn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79fe9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CIFAR-10 dataset (train and test)\n",
    "train_dataset = subset_data(CIFAR10(root=ROOT_DIR, train=True, download=True, transform=DEFAULT_TRANSFORM), 5000)\n",
    "test_dataset = CIFAR10(root=ROOT_DIR, train=False, download=True, transform=DEFAULT_TRANSFORM)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87437475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import dtype as T_dtype\n",
    "from torch.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "QCONFIG = get_default_qconfig('fbgemm')\n",
    "QCONFIG_DEFAULT = {\n",
    "    \"\": QCONFIG,\n",
    "    \"object_type\": [\n",
    "        (torch.nn.Conv2d, QCONFIG),\n",
    "        (torch.nn.Linear, QCONFIG),\n",
    "        (torch.nn.ReLU, QCONFIG),\n",
    "        (torch.nn.BatchNorm2d, QCONFIG),\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def quantise_dynamic(\n",
    "        model: nn.Module,\n",
    "        spec: tuple = {torch.nn.Linear},\n",
    "        dtype: T_dtype = torch.qint8,\n",
    "    ) -> nn.Module:\n",
    "    return torch.quantization.quantize_dynamic(\n",
    "        model, spec, dtype=dtype,\n",
    "    )\n",
    "\n",
    "def quantise_static(\n",
    "        model: nn.Module,\n",
    "        calibration_loader: DataLoader,\n",
    "        qconfig_dict: dict = QCONFIG_DEFAULT,\n",
    "    ) -> nn.Module:\n",
    "    model = model.to('cpu')\n",
    "    example_inputs = (next(iter(calibration_loader))[0],)\n",
    "    prepared_model = prepare_fx(model, qconfig_dict, example_inputs)\n",
    "    return convert_fx(prepared_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e67a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c9f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20171f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703468e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
      "  prepared = prepare(\n",
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1318: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): QuantizedConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "  (dense1): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(96, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(160, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(192, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(224, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans1): Module(\n",
      "    (bn): QuantizedBNReLU2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "  )\n",
      "  (dense2): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(160, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(192, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(224, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(288, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Module(\n",
      "      (bn1): QuantizedBNReLU2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(320, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Module(\n",
      "      (bn1): QuantizedBNReLU2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(352, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Module(\n",
      "      (bn1): QuantizedBNReLU2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(384, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Module(\n",
      "      (bn1): QuantizedBNReLU2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(416, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Module(\n",
      "      (bn1): QuantizedBNReLU2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(448, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Module(\n",
      "      (bn1): QuantizedBNReLU2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(480, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans2): Module(\n",
      "    (bn): QuantizedBNReLU2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): QuantizedConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "  )\n",
      "  (dense3): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(288, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(320, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(352, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(384, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(416, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Module(\n",
      "      (bn1): QuantizedBNReLU2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(448, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Module(\n",
      "      (bn1): QuantizedBNReLU2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(480, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Module(\n",
      "      (bn1): QuantizedBNReLU2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Module(\n",
      "      (bn1): QuantizedBNReLU2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(544, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Module(\n",
      "      (bn1): QuantizedBNReLU2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(576, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Module(\n",
      "      (bn1): QuantizedBNReLU2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(608, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Module(\n",
      "      (bn1): QuantizedBNReLU2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(640, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Module(\n",
      "      (bn1): QuantizedBNReLU2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(672, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Module(\n",
      "      (bn1): QuantizedBNReLU2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(704, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Module(\n",
      "      (bn1): QuantizedBNReLU2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(736, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (16): Module(\n",
      "      (bn1): QuantizedBNReLU2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (17): Module(\n",
      "      (bn1): QuantizedBNReLU2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(800, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (18): Module(\n",
      "      (bn1): QuantizedBNReLU2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(832, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (19): Module(\n",
      "      (bn1): QuantizedBNReLU2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(864, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (20): Module(\n",
      "      (bn1): QuantizedBNReLU2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(896, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (21): Module(\n",
      "      (bn1): QuantizedBNReLU2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(928, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (22): Module(\n",
      "      (bn1): QuantizedBNReLU2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(960, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (23): Module(\n",
      "      (bn1): QuantizedBNReLU2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(992, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans3): Module(\n",
      "    (bn): QuantizedBNReLU2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): QuantizedConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0, bias=False)\n",
      "  )\n",
      "  (dense4): Module(\n",
      "    (0): Module(\n",
      "      (bn1): QuantizedBNReLU2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (bn1): QuantizedBNReLU2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(544, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Module(\n",
      "      (bn1): QuantizedBNReLU2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(576, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Module(\n",
      "      (bn1): QuantizedBNReLU2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(608, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Module(\n",
      "      (bn1): QuantizedBNReLU2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(640, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Module(\n",
      "      (bn1): QuantizedBNReLU2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(672, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Module(\n",
      "      (bn1): QuantizedBNReLU2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(704, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Module(\n",
      "      (bn1): QuantizedBNReLU2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(736, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Module(\n",
      "      (bn1): QuantizedBNReLU2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Module(\n",
      "      (bn1): QuantizedBNReLU2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(800, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Module(\n",
      "      (bn1): QuantizedBNReLU2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(832, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Module(\n",
      "      (bn1): QuantizedBNReLU2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(864, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Module(\n",
      "      (bn1): QuantizedBNReLU2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(896, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Module(\n",
      "      (bn1): QuantizedBNReLU2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(928, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Module(\n",
      "      (bn1): QuantizedBNReLU2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(960, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Module(\n",
      "      (bn1): QuantizedBNReLU2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): QuantizedConvReLU2d(992, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "      (conv2): QuantizedConv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (bn): QuantizedBNReLU2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear): QuantizedLinear(in_features=1024, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1_input_scale_0 = self.conv1_input_scale_0\n",
      "    conv1_input_zero_point_0 = self.conv1_input_zero_point_0\n",
      "    quantize_per_tensor = torch.quantize_per_tensor(x, conv1_input_scale_0, conv1_input_zero_point_0, torch.quint8);  x = conv1_input_scale_0 = conv1_input_zero_point_0 = None\n",
      "    conv1 = self.conv1(quantize_per_tensor);  quantize_per_tensor = None\n",
      "    dense1_0_bn1 = getattr(self.dense1, \"0\").bn1(conv1)\n",
      "    dense1_0_conv1 = getattr(self.dense1, \"0\").conv1(dense1_0_bn1);  dense1_0_bn1 = None\n",
      "    dense1_0_conv2 = getattr(self.dense1, \"0\").conv2(dense1_0_conv1);  dense1_0_conv1 = None\n",
      "    cat = torch.cat([dense1_0_conv2, conv1], 1);  dense1_0_conv2 = conv1 = None\n",
      "    dense1_1_bn1 = getattr(self.dense1, \"1\").bn1(cat)\n",
      "    dense1_1_conv1 = getattr(self.dense1, \"1\").conv1(dense1_1_bn1);  dense1_1_bn1 = None\n",
      "    dense1_1_conv2 = getattr(self.dense1, \"1\").conv2(dense1_1_conv1);  dense1_1_conv1 = None\n",
      "    cat_1 = torch.cat([dense1_1_conv2, cat], 1);  dense1_1_conv2 = cat = None\n",
      "    dense1_2_bn1 = getattr(self.dense1, \"2\").bn1(cat_1)\n",
      "    dense1_2_conv1 = getattr(self.dense1, \"2\").conv1(dense1_2_bn1);  dense1_2_bn1 = None\n",
      "    dense1_2_conv2 = getattr(self.dense1, \"2\").conv2(dense1_2_conv1);  dense1_2_conv1 = None\n",
      "    cat_2 = torch.cat([dense1_2_conv2, cat_1], 1);  dense1_2_conv2 = cat_1 = None\n",
      "    dense1_3_bn1 = getattr(self.dense1, \"3\").bn1(cat_2)\n",
      "    dense1_3_conv1 = getattr(self.dense1, \"3\").conv1(dense1_3_bn1);  dense1_3_bn1 = None\n",
      "    dense1_3_conv2 = getattr(self.dense1, \"3\").conv2(dense1_3_conv1);  dense1_3_conv1 = None\n",
      "    cat_3 = torch.cat([dense1_3_conv2, cat_2], 1);  dense1_3_conv2 = cat_2 = None\n",
      "    dense1_4_bn1 = getattr(self.dense1, \"4\").bn1(cat_3)\n",
      "    dense1_4_conv1 = getattr(self.dense1, \"4\").conv1(dense1_4_bn1);  dense1_4_bn1 = None\n",
      "    dense1_4_conv2 = getattr(self.dense1, \"4\").conv2(dense1_4_conv1);  dense1_4_conv1 = None\n",
      "    cat_4 = torch.cat([dense1_4_conv2, cat_3], 1);  dense1_4_conv2 = cat_3 = None\n",
      "    dense1_5_bn1 = getattr(self.dense1, \"5\").bn1(cat_4)\n",
      "    dense1_5_conv1 = getattr(self.dense1, \"5\").conv1(dense1_5_bn1);  dense1_5_bn1 = None\n",
      "    dense1_5_conv2 = getattr(self.dense1, \"5\").conv2(dense1_5_conv1);  dense1_5_conv1 = None\n",
      "    cat_5 = torch.cat([dense1_5_conv2, cat_4], 1);  dense1_5_conv2 = cat_4 = None\n",
      "    trans1_bn = self.trans1.bn(cat_5);  cat_5 = None\n",
      "    trans1_conv = self.trans1.conv(trans1_bn);  trans1_bn = None\n",
      "    avg_pool2d = torch._C._nn.avg_pool2d(trans1_conv, 2);  trans1_conv = None\n",
      "    dense2_0_bn1 = getattr(self.dense2, \"0\").bn1(avg_pool2d)\n",
      "    dense2_0_conv1 = getattr(self.dense2, \"0\").conv1(dense2_0_bn1);  dense2_0_bn1 = None\n",
      "    dense2_0_conv2 = getattr(self.dense2, \"0\").conv2(dense2_0_conv1);  dense2_0_conv1 = None\n",
      "    cat_6 = torch.cat([dense2_0_conv2, avg_pool2d], 1);  dense2_0_conv2 = avg_pool2d = None\n",
      "    dense2_1_bn1 = getattr(self.dense2, \"1\").bn1(cat_6)\n",
      "    dense2_1_conv1 = getattr(self.dense2, \"1\").conv1(dense2_1_bn1);  dense2_1_bn1 = None\n",
      "    dense2_1_conv2 = getattr(self.dense2, \"1\").conv2(dense2_1_conv1);  dense2_1_conv1 = None\n",
      "    cat_7 = torch.cat([dense2_1_conv2, cat_6], 1);  dense2_1_conv2 = cat_6 = None\n",
      "    dense2_2_bn1 = getattr(self.dense2, \"2\").bn1(cat_7)\n",
      "    dense2_2_conv1 = getattr(self.dense2, \"2\").conv1(dense2_2_bn1);  dense2_2_bn1 = None\n",
      "    dense2_2_conv2 = getattr(self.dense2, \"2\").conv2(dense2_2_conv1);  dense2_2_conv1 = None\n",
      "    cat_8 = torch.cat([dense2_2_conv2, cat_7], 1);  dense2_2_conv2 = cat_7 = None\n",
      "    dense2_3_bn1 = getattr(self.dense2, \"3\").bn1(cat_8)\n",
      "    dense2_3_conv1 = getattr(self.dense2, \"3\").conv1(dense2_3_bn1);  dense2_3_bn1 = None\n",
      "    dense2_3_conv2 = getattr(self.dense2, \"3\").conv2(dense2_3_conv1);  dense2_3_conv1 = None\n",
      "    cat_9 = torch.cat([dense2_3_conv2, cat_8], 1);  dense2_3_conv2 = cat_8 = None\n",
      "    dense2_4_bn1 = getattr(self.dense2, \"4\").bn1(cat_9)\n",
      "    dense2_4_conv1 = getattr(self.dense2, \"4\").conv1(dense2_4_bn1);  dense2_4_bn1 = None\n",
      "    dense2_4_conv2 = getattr(self.dense2, \"4\").conv2(dense2_4_conv1);  dense2_4_conv1 = None\n",
      "    cat_10 = torch.cat([dense2_4_conv2, cat_9], 1);  dense2_4_conv2 = cat_9 = None\n",
      "    dense2_5_bn1 = getattr(self.dense2, \"5\").bn1(cat_10)\n",
      "    dense2_5_conv1 = getattr(self.dense2, \"5\").conv1(dense2_5_bn1);  dense2_5_bn1 = None\n",
      "    dense2_5_conv2 = getattr(self.dense2, \"5\").conv2(dense2_5_conv1);  dense2_5_conv1 = None\n",
      "    cat_11 = torch.cat([dense2_5_conv2, cat_10], 1);  dense2_5_conv2 = cat_10 = None\n",
      "    dense2_6_bn1 = getattr(self.dense2, \"6\").bn1(cat_11)\n",
      "    dense2_6_conv1 = getattr(self.dense2, \"6\").conv1(dense2_6_bn1);  dense2_6_bn1 = None\n",
      "    dense2_6_conv2 = getattr(self.dense2, \"6\").conv2(dense2_6_conv1);  dense2_6_conv1 = None\n",
      "    cat_12 = torch.cat([dense2_6_conv2, cat_11], 1);  dense2_6_conv2 = cat_11 = None\n",
      "    dense2_7_bn1 = getattr(self.dense2, \"7\").bn1(cat_12)\n",
      "    dense2_7_conv1 = getattr(self.dense2, \"7\").conv1(dense2_7_bn1);  dense2_7_bn1 = None\n",
      "    dense2_7_conv2 = getattr(self.dense2, \"7\").conv2(dense2_7_conv1);  dense2_7_conv1 = None\n",
      "    cat_13 = torch.cat([dense2_7_conv2, cat_12], 1);  dense2_7_conv2 = cat_12 = None\n",
      "    dense2_8_bn1 = getattr(self.dense2, \"8\").bn1(cat_13)\n",
      "    dense2_8_conv1 = getattr(self.dense2, \"8\").conv1(dense2_8_bn1);  dense2_8_bn1 = None\n",
      "    dense2_8_conv2 = getattr(self.dense2, \"8\").conv2(dense2_8_conv1);  dense2_8_conv1 = None\n",
      "    cat_14 = torch.cat([dense2_8_conv2, cat_13], 1);  dense2_8_conv2 = cat_13 = None\n",
      "    dense2_9_bn1 = getattr(self.dense2, \"9\").bn1(cat_14)\n",
      "    dense2_9_conv1 = getattr(self.dense2, \"9\").conv1(dense2_9_bn1);  dense2_9_bn1 = None\n",
      "    dense2_9_conv2 = getattr(self.dense2, \"9\").conv2(dense2_9_conv1);  dense2_9_conv1 = None\n",
      "    cat_15 = torch.cat([dense2_9_conv2, cat_14], 1);  dense2_9_conv2 = cat_14 = None\n",
      "    dense2_10_bn1 = getattr(self.dense2, \"10\").bn1(cat_15)\n",
      "    dense2_10_conv1 = getattr(self.dense2, \"10\").conv1(dense2_10_bn1);  dense2_10_bn1 = None\n",
      "    dense2_10_conv2 = getattr(self.dense2, \"10\").conv2(dense2_10_conv1);  dense2_10_conv1 = None\n",
      "    cat_16 = torch.cat([dense2_10_conv2, cat_15], 1);  dense2_10_conv2 = cat_15 = None\n",
      "    dense2_11_bn1 = getattr(self.dense2, \"11\").bn1(cat_16)\n",
      "    dense2_11_conv1 = getattr(self.dense2, \"11\").conv1(dense2_11_bn1);  dense2_11_bn1 = None\n",
      "    dense2_11_conv2 = getattr(self.dense2, \"11\").conv2(dense2_11_conv1);  dense2_11_conv1 = None\n",
      "    cat_17 = torch.cat([dense2_11_conv2, cat_16], 1);  dense2_11_conv2 = cat_16 = None\n",
      "    trans2_bn = self.trans2.bn(cat_17);  cat_17 = None\n",
      "    trans2_conv = self.trans2.conv(trans2_bn);  trans2_bn = None\n",
      "    avg_pool2d_1 = torch._C._nn.avg_pool2d(trans2_conv, 2);  trans2_conv = None\n",
      "    dense3_0_bn1 = getattr(self.dense3, \"0\").bn1(avg_pool2d_1)\n",
      "    dense3_0_conv1 = getattr(self.dense3, \"0\").conv1(dense3_0_bn1);  dense3_0_bn1 = None\n",
      "    dense3_0_conv2 = getattr(self.dense3, \"0\").conv2(dense3_0_conv1);  dense3_0_conv1 = None\n",
      "    cat_18 = torch.cat([dense3_0_conv2, avg_pool2d_1], 1);  dense3_0_conv2 = avg_pool2d_1 = None\n",
      "    dense3_1_bn1 = getattr(self.dense3, \"1\").bn1(cat_18)\n",
      "    dense3_1_conv1 = getattr(self.dense3, \"1\").conv1(dense3_1_bn1);  dense3_1_bn1 = None\n",
      "    dense3_1_conv2 = getattr(self.dense3, \"1\").conv2(dense3_1_conv1);  dense3_1_conv1 = None\n",
      "    cat_19 = torch.cat([dense3_1_conv2, cat_18], 1);  dense3_1_conv2 = cat_18 = None\n",
      "    dense3_2_bn1 = getattr(self.dense3, \"2\").bn1(cat_19)\n",
      "    dense3_2_conv1 = getattr(self.dense3, \"2\").conv1(dense3_2_bn1);  dense3_2_bn1 = None\n",
      "    dense3_2_conv2 = getattr(self.dense3, \"2\").conv2(dense3_2_conv1);  dense3_2_conv1 = None\n",
      "    cat_20 = torch.cat([dense3_2_conv2, cat_19], 1);  dense3_2_conv2 = cat_19 = None\n",
      "    dense3_3_bn1 = getattr(self.dense3, \"3\").bn1(cat_20)\n",
      "    dense3_3_conv1 = getattr(self.dense3, \"3\").conv1(dense3_3_bn1);  dense3_3_bn1 = None\n",
      "    dense3_3_conv2 = getattr(self.dense3, \"3\").conv2(dense3_3_conv1);  dense3_3_conv1 = None\n",
      "    cat_21 = torch.cat([dense3_3_conv2, cat_20], 1);  dense3_3_conv2 = cat_20 = None\n",
      "    dense3_4_bn1 = getattr(self.dense3, \"4\").bn1(cat_21)\n",
      "    dense3_4_conv1 = getattr(self.dense3, \"4\").conv1(dense3_4_bn1);  dense3_4_bn1 = None\n",
      "    dense3_4_conv2 = getattr(self.dense3, \"4\").conv2(dense3_4_conv1);  dense3_4_conv1 = None\n",
      "    cat_22 = torch.cat([dense3_4_conv2, cat_21], 1);  dense3_4_conv2 = cat_21 = None\n",
      "    dense3_5_bn1 = getattr(self.dense3, \"5\").bn1(cat_22)\n",
      "    dense3_5_conv1 = getattr(self.dense3, \"5\").conv1(dense3_5_bn1);  dense3_5_bn1 = None\n",
      "    dense3_5_conv2 = getattr(self.dense3, \"5\").conv2(dense3_5_conv1);  dense3_5_conv1 = None\n",
      "    cat_23 = torch.cat([dense3_5_conv2, cat_22], 1);  dense3_5_conv2 = cat_22 = None\n",
      "    dense3_6_bn1 = getattr(self.dense3, \"6\").bn1(cat_23)\n",
      "    dense3_6_conv1 = getattr(self.dense3, \"6\").conv1(dense3_6_bn1);  dense3_6_bn1 = None\n",
      "    dense3_6_conv2 = getattr(self.dense3, \"6\").conv2(dense3_6_conv1);  dense3_6_conv1 = None\n",
      "    cat_24 = torch.cat([dense3_6_conv2, cat_23], 1);  dense3_6_conv2 = cat_23 = None\n",
      "    dense3_7_bn1 = getattr(self.dense3, \"7\").bn1(cat_24)\n",
      "    dense3_7_conv1 = getattr(self.dense3, \"7\").conv1(dense3_7_bn1);  dense3_7_bn1 = None\n",
      "    dense3_7_conv2 = getattr(self.dense3, \"7\").conv2(dense3_7_conv1);  dense3_7_conv1 = None\n",
      "    cat_25 = torch.cat([dense3_7_conv2, cat_24], 1);  dense3_7_conv2 = cat_24 = None\n",
      "    dense3_8_bn1 = getattr(self.dense3, \"8\").bn1(cat_25)\n",
      "    dense3_8_conv1 = getattr(self.dense3, \"8\").conv1(dense3_8_bn1);  dense3_8_bn1 = None\n",
      "    dense3_8_conv2 = getattr(self.dense3, \"8\").conv2(dense3_8_conv1);  dense3_8_conv1 = None\n",
      "    cat_26 = torch.cat([dense3_8_conv2, cat_25], 1);  dense3_8_conv2 = cat_25 = None\n",
      "    dense3_9_bn1 = getattr(self.dense3, \"9\").bn1(cat_26)\n",
      "    dense3_9_conv1 = getattr(self.dense3, \"9\").conv1(dense3_9_bn1);  dense3_9_bn1 = None\n",
      "    dense3_9_conv2 = getattr(self.dense3, \"9\").conv2(dense3_9_conv1);  dense3_9_conv1 = None\n",
      "    cat_27 = torch.cat([dense3_9_conv2, cat_26], 1);  dense3_9_conv2 = cat_26 = None\n",
      "    dense3_10_bn1 = getattr(self.dense3, \"10\").bn1(cat_27)\n",
      "    dense3_10_conv1 = getattr(self.dense3, \"10\").conv1(dense3_10_bn1);  dense3_10_bn1 = None\n",
      "    dense3_10_conv2 = getattr(self.dense3, \"10\").conv2(dense3_10_conv1);  dense3_10_conv1 = None\n",
      "    cat_28 = torch.cat([dense3_10_conv2, cat_27], 1);  dense3_10_conv2 = cat_27 = None\n",
      "    dense3_11_bn1 = getattr(self.dense3, \"11\").bn1(cat_28)\n",
      "    dense3_11_conv1 = getattr(self.dense3, \"11\").conv1(dense3_11_bn1);  dense3_11_bn1 = None\n",
      "    dense3_11_conv2 = getattr(self.dense3, \"11\").conv2(dense3_11_conv1);  dense3_11_conv1 = None\n",
      "    cat_29 = torch.cat([dense3_11_conv2, cat_28], 1);  dense3_11_conv2 = cat_28 = None\n",
      "    dense3_12_bn1 = getattr(self.dense3, \"12\").bn1(cat_29)\n",
      "    dense3_12_conv1 = getattr(self.dense3, \"12\").conv1(dense3_12_bn1);  dense3_12_bn1 = None\n",
      "    dense3_12_conv2 = getattr(self.dense3, \"12\").conv2(dense3_12_conv1);  dense3_12_conv1 = None\n",
      "    cat_30 = torch.cat([dense3_12_conv2, cat_29], 1);  dense3_12_conv2 = cat_29 = None\n",
      "    dense3_13_bn1 = getattr(self.dense3, \"13\").bn1(cat_30)\n",
      "    dense3_13_conv1 = getattr(self.dense3, \"13\").conv1(dense3_13_bn1);  dense3_13_bn1 = None\n",
      "    dense3_13_conv2 = getattr(self.dense3, \"13\").conv2(dense3_13_conv1);  dense3_13_conv1 = None\n",
      "    cat_31 = torch.cat([dense3_13_conv2, cat_30], 1);  dense3_13_conv2 = cat_30 = None\n",
      "    dense3_14_bn1 = getattr(self.dense3, \"14\").bn1(cat_31)\n",
      "    dense3_14_conv1 = getattr(self.dense3, \"14\").conv1(dense3_14_bn1);  dense3_14_bn1 = None\n",
      "    dense3_14_conv2 = getattr(self.dense3, \"14\").conv2(dense3_14_conv1);  dense3_14_conv1 = None\n",
      "    cat_32 = torch.cat([dense3_14_conv2, cat_31], 1);  dense3_14_conv2 = cat_31 = None\n",
      "    dense3_15_bn1 = getattr(self.dense3, \"15\").bn1(cat_32)\n",
      "    dense3_15_conv1 = getattr(self.dense3, \"15\").conv1(dense3_15_bn1);  dense3_15_bn1 = None\n",
      "    dense3_15_conv2 = getattr(self.dense3, \"15\").conv2(dense3_15_conv1);  dense3_15_conv1 = None\n",
      "    cat_33 = torch.cat([dense3_15_conv2, cat_32], 1);  dense3_15_conv2 = cat_32 = None\n",
      "    dense3_16_bn1 = getattr(self.dense3, \"16\").bn1(cat_33)\n",
      "    dense3_16_conv1 = getattr(self.dense3, \"16\").conv1(dense3_16_bn1);  dense3_16_bn1 = None\n",
      "    dense3_16_conv2 = getattr(self.dense3, \"16\").conv2(dense3_16_conv1);  dense3_16_conv1 = None\n",
      "    cat_34 = torch.cat([dense3_16_conv2, cat_33], 1);  dense3_16_conv2 = cat_33 = None\n",
      "    dense3_17_bn1 = getattr(self.dense3, \"17\").bn1(cat_34)\n",
      "    dense3_17_conv1 = getattr(self.dense3, \"17\").conv1(dense3_17_bn1);  dense3_17_bn1 = None\n",
      "    dense3_17_conv2 = getattr(self.dense3, \"17\").conv2(dense3_17_conv1);  dense3_17_conv1 = None\n",
      "    cat_35 = torch.cat([dense3_17_conv2, cat_34], 1);  dense3_17_conv2 = cat_34 = None\n",
      "    dense3_18_bn1 = getattr(self.dense3, \"18\").bn1(cat_35)\n",
      "    dense3_18_conv1 = getattr(self.dense3, \"18\").conv1(dense3_18_bn1);  dense3_18_bn1 = None\n",
      "    dense3_18_conv2 = getattr(self.dense3, \"18\").conv2(dense3_18_conv1);  dense3_18_conv1 = None\n",
      "    cat_36 = torch.cat([dense3_18_conv2, cat_35], 1);  dense3_18_conv2 = cat_35 = None\n",
      "    dense3_19_bn1 = getattr(self.dense3, \"19\").bn1(cat_36)\n",
      "    dense3_19_conv1 = getattr(self.dense3, \"19\").conv1(dense3_19_bn1);  dense3_19_bn1 = None\n",
      "    dense3_19_conv2 = getattr(self.dense3, \"19\").conv2(dense3_19_conv1);  dense3_19_conv1 = None\n",
      "    cat_37 = torch.cat([dense3_19_conv2, cat_36], 1);  dense3_19_conv2 = cat_36 = None\n",
      "    dense3_20_bn1 = getattr(self.dense3, \"20\").bn1(cat_37)\n",
      "    dense3_20_conv1 = getattr(self.dense3, \"20\").conv1(dense3_20_bn1);  dense3_20_bn1 = None\n",
      "    dense3_20_conv2 = getattr(self.dense3, \"20\").conv2(dense3_20_conv1);  dense3_20_conv1 = None\n",
      "    cat_38 = torch.cat([dense3_20_conv2, cat_37], 1);  dense3_20_conv2 = cat_37 = None\n",
      "    dense3_21_bn1 = getattr(self.dense3, \"21\").bn1(cat_38)\n",
      "    dense3_21_conv1 = getattr(self.dense3, \"21\").conv1(dense3_21_bn1);  dense3_21_bn1 = None\n",
      "    dense3_21_conv2 = getattr(self.dense3, \"21\").conv2(dense3_21_conv1);  dense3_21_conv1 = None\n",
      "    cat_39 = torch.cat([dense3_21_conv2, cat_38], 1);  dense3_21_conv2 = cat_38 = None\n",
      "    dense3_22_bn1 = getattr(self.dense3, \"22\").bn1(cat_39)\n",
      "    dense3_22_conv1 = getattr(self.dense3, \"22\").conv1(dense3_22_bn1);  dense3_22_bn1 = None\n",
      "    dense3_22_conv2 = getattr(self.dense3, \"22\").conv2(dense3_22_conv1);  dense3_22_conv1 = None\n",
      "    cat_40 = torch.cat([dense3_22_conv2, cat_39], 1);  dense3_22_conv2 = cat_39 = None\n",
      "    dense3_23_bn1 = getattr(self.dense3, \"23\").bn1(cat_40)\n",
      "    dense3_23_conv1 = getattr(self.dense3, \"23\").conv1(dense3_23_bn1);  dense3_23_bn1 = None\n",
      "    dense3_23_conv2 = getattr(self.dense3, \"23\").conv2(dense3_23_conv1);  dense3_23_conv1 = None\n",
      "    cat_41 = torch.cat([dense3_23_conv2, cat_40], 1);  dense3_23_conv2 = cat_40 = None\n",
      "    trans3_bn = self.trans3.bn(cat_41);  cat_41 = None\n",
      "    trans3_conv = self.trans3.conv(trans3_bn);  trans3_bn = None\n",
      "    avg_pool2d_2 = torch._C._nn.avg_pool2d(trans3_conv, 2);  trans3_conv = None\n",
      "    dense4_0_bn1 = getattr(self.dense4, \"0\").bn1(avg_pool2d_2)\n",
      "    dense4_0_conv1 = getattr(self.dense4, \"0\").conv1(dense4_0_bn1);  dense4_0_bn1 = None\n",
      "    dense4_0_conv2 = getattr(self.dense4, \"0\").conv2(dense4_0_conv1);  dense4_0_conv1 = None\n",
      "    cat_42 = torch.cat([dense4_0_conv2, avg_pool2d_2], 1);  dense4_0_conv2 = avg_pool2d_2 = None\n",
      "    dense4_1_bn1 = getattr(self.dense4, \"1\").bn1(cat_42)\n",
      "    dense4_1_conv1 = getattr(self.dense4, \"1\").conv1(dense4_1_bn1);  dense4_1_bn1 = None\n",
      "    dense4_1_conv2 = getattr(self.dense4, \"1\").conv2(dense4_1_conv1);  dense4_1_conv1 = None\n",
      "    cat_43 = torch.cat([dense4_1_conv2, cat_42], 1);  dense4_1_conv2 = cat_42 = None\n",
      "    dense4_2_bn1 = getattr(self.dense4, \"2\").bn1(cat_43)\n",
      "    dense4_2_conv1 = getattr(self.dense4, \"2\").conv1(dense4_2_bn1);  dense4_2_bn1 = None\n",
      "    dense4_2_conv2 = getattr(self.dense4, \"2\").conv2(dense4_2_conv1);  dense4_2_conv1 = None\n",
      "    cat_44 = torch.cat([dense4_2_conv2, cat_43], 1);  dense4_2_conv2 = cat_43 = None\n",
      "    dense4_3_bn1 = getattr(self.dense4, \"3\").bn1(cat_44)\n",
      "    dense4_3_conv1 = getattr(self.dense4, \"3\").conv1(dense4_3_bn1);  dense4_3_bn1 = None\n",
      "    dense4_3_conv2 = getattr(self.dense4, \"3\").conv2(dense4_3_conv1);  dense4_3_conv1 = None\n",
      "    cat_45 = torch.cat([dense4_3_conv2, cat_44], 1);  dense4_3_conv2 = cat_44 = None\n",
      "    dense4_4_bn1 = getattr(self.dense4, \"4\").bn1(cat_45)\n",
      "    dense4_4_conv1 = getattr(self.dense4, \"4\").conv1(dense4_4_bn1);  dense4_4_bn1 = None\n",
      "    dense4_4_conv2 = getattr(self.dense4, \"4\").conv2(dense4_4_conv1);  dense4_4_conv1 = None\n",
      "    cat_46 = torch.cat([dense4_4_conv2, cat_45], 1);  dense4_4_conv2 = cat_45 = None\n",
      "    dense4_5_bn1 = getattr(self.dense4, \"5\").bn1(cat_46)\n",
      "    dense4_5_conv1 = getattr(self.dense4, \"5\").conv1(dense4_5_bn1);  dense4_5_bn1 = None\n",
      "    dense4_5_conv2 = getattr(self.dense4, \"5\").conv2(dense4_5_conv1);  dense4_5_conv1 = None\n",
      "    cat_47 = torch.cat([dense4_5_conv2, cat_46], 1);  dense4_5_conv2 = cat_46 = None\n",
      "    dense4_6_bn1 = getattr(self.dense4, \"6\").bn1(cat_47)\n",
      "    dense4_6_conv1 = getattr(self.dense4, \"6\").conv1(dense4_6_bn1);  dense4_6_bn1 = None\n",
      "    dense4_6_conv2 = getattr(self.dense4, \"6\").conv2(dense4_6_conv1);  dense4_6_conv1 = None\n",
      "    cat_48 = torch.cat([dense4_6_conv2, cat_47], 1);  dense4_6_conv2 = cat_47 = None\n",
      "    dense4_7_bn1 = getattr(self.dense4, \"7\").bn1(cat_48)\n",
      "    dense4_7_conv1 = getattr(self.dense4, \"7\").conv1(dense4_7_bn1);  dense4_7_bn1 = None\n",
      "    dense4_7_conv2 = getattr(self.dense4, \"7\").conv2(dense4_7_conv1);  dense4_7_conv1 = None\n",
      "    cat_49 = torch.cat([dense4_7_conv2, cat_48], 1);  dense4_7_conv2 = cat_48 = None\n",
      "    dense4_8_bn1 = getattr(self.dense4, \"8\").bn1(cat_49)\n",
      "    dense4_8_conv1 = getattr(self.dense4, \"8\").conv1(dense4_8_bn1);  dense4_8_bn1 = None\n",
      "    dense4_8_conv2 = getattr(self.dense4, \"8\").conv2(dense4_8_conv1);  dense4_8_conv1 = None\n",
      "    cat_50 = torch.cat([dense4_8_conv2, cat_49], 1);  dense4_8_conv2 = cat_49 = None\n",
      "    dense4_9_bn1 = getattr(self.dense4, \"9\").bn1(cat_50)\n",
      "    dense4_9_conv1 = getattr(self.dense4, \"9\").conv1(dense4_9_bn1);  dense4_9_bn1 = None\n",
      "    dense4_9_conv2 = getattr(self.dense4, \"9\").conv2(dense4_9_conv1);  dense4_9_conv1 = None\n",
      "    cat_51 = torch.cat([dense4_9_conv2, cat_50], 1);  dense4_9_conv2 = cat_50 = None\n",
      "    dense4_10_bn1 = getattr(self.dense4, \"10\").bn1(cat_51)\n",
      "    dense4_10_conv1 = getattr(self.dense4, \"10\").conv1(dense4_10_bn1);  dense4_10_bn1 = None\n",
      "    dense4_10_conv2 = getattr(self.dense4, \"10\").conv2(dense4_10_conv1);  dense4_10_conv1 = None\n",
      "    cat_52 = torch.cat([dense4_10_conv2, cat_51], 1);  dense4_10_conv2 = cat_51 = None\n",
      "    dense4_11_bn1 = getattr(self.dense4, \"11\").bn1(cat_52)\n",
      "    dense4_11_conv1 = getattr(self.dense4, \"11\").conv1(dense4_11_bn1);  dense4_11_bn1 = None\n",
      "    dense4_11_conv2 = getattr(self.dense4, \"11\").conv2(dense4_11_conv1);  dense4_11_conv1 = None\n",
      "    cat_53 = torch.cat([dense4_11_conv2, cat_52], 1);  dense4_11_conv2 = cat_52 = None\n",
      "    dense4_12_bn1 = getattr(self.dense4, \"12\").bn1(cat_53)\n",
      "    dense4_12_conv1 = getattr(self.dense4, \"12\").conv1(dense4_12_bn1);  dense4_12_bn1 = None\n",
      "    dense4_12_conv2 = getattr(self.dense4, \"12\").conv2(dense4_12_conv1);  dense4_12_conv1 = None\n",
      "    cat_54 = torch.cat([dense4_12_conv2, cat_53], 1);  dense4_12_conv2 = cat_53 = None\n",
      "    dense4_13_bn1 = getattr(self.dense4, \"13\").bn1(cat_54)\n",
      "    dense4_13_conv1 = getattr(self.dense4, \"13\").conv1(dense4_13_bn1);  dense4_13_bn1 = None\n",
      "    dense4_13_conv2 = getattr(self.dense4, \"13\").conv2(dense4_13_conv1);  dense4_13_conv1 = None\n",
      "    cat_55 = torch.cat([dense4_13_conv2, cat_54], 1);  dense4_13_conv2 = cat_54 = None\n",
      "    dense4_14_bn1 = getattr(self.dense4, \"14\").bn1(cat_55)\n",
      "    dense4_14_conv1 = getattr(self.dense4, \"14\").conv1(dense4_14_bn1);  dense4_14_bn1 = None\n",
      "    dense4_14_conv2 = getattr(self.dense4, \"14\").conv2(dense4_14_conv1);  dense4_14_conv1 = None\n",
      "    cat_56 = torch.cat([dense4_14_conv2, cat_55], 1);  dense4_14_conv2 = cat_55 = None\n",
      "    dense4_15_bn1 = getattr(self.dense4, \"15\").bn1(cat_56)\n",
      "    dense4_15_conv1 = getattr(self.dense4, \"15\").conv1(dense4_15_bn1);  dense4_15_bn1 = None\n",
      "    dense4_15_conv2 = getattr(self.dense4, \"15\").conv2(dense4_15_conv1);  dense4_15_conv1 = None\n",
      "    cat_57 = torch.cat([dense4_15_conv2, cat_56], 1);  dense4_15_conv2 = cat_56 = None\n",
      "    bn = self.bn(cat_57);  cat_57 = None\n",
      "    avg_pool2d_3 = torch._C._nn.avg_pool2d(bn, 4);  bn = None\n",
      "    size = avg_pool2d_3.size(0)\n",
      "    view = avg_pool2d_3.view(size, -1);  avg_pool2d_3 = size = None\n",
      "    linear = self.linear(view);  view = None\n",
      "    dequantize_246 = linear.dequantize();  linear = None\n",
      "    return dequantize_246\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx\n",
    "\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "example_inputs = (next(iter(train_loader))[0],)\n",
    "prepared_model = prepare_fx(model, qconfig_dict, example_inputs)\n",
    "quantized_model = convert_fx(prepared_model)\n",
    "\n",
    "print(quantized_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27b3dfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 7.89627\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a419d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "for m in model.modules():\n",
    "    if isinstance(m, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        m.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        torch.quantization.prepare(m, inplace=True)\n",
    "        torch.quantization.convert(m, inplace=True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a3aeef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (dense1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans1): Transition(\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans2): Transition(\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans3): Transition(\n",
      "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62ba7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "483ad031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 28.353676\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f10c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834fdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3e08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(test_loader, model, criterion, \"cuda\", half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c032e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mymodelbc = BC(model)\n",
    "optimiser = optim.SGD(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = \"cuda\"\n",
    "\n",
    "train_loader = get_train_cifar10(transform_test, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c65ce25",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m optimiser.step()\n\u001b[32m     19\u001b[39m mymodelbc.clip()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m total += targets.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "best_acc = 0\n",
    "start_epoch = 0\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+n_epochs):\n",
    "    mymodelbc.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        outputs = mymodelbc(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        mymodelbc.clip()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "372910f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train\n",
    "\n",
    "\n",
    "def quantise_aware_train(\n",
    "        train_loader: DataLoader,\n",
    "        model: nn.Module,\n",
    "        optimiser: \"Optimizer\",\n",
    "        criterion,\n",
    "        qconfig: str = \"fbgemm\",\n",
    "        device: str = \"cuda\",\n",
    "        n_epochs: int = 500,\n",
    "    ) -> None:\n",
    "    model.qconfig = torch.quantization.get_default_qat_qconfig(qconfig)\n",
    "    torch.quantization.prepare_qat(model, inplace=True)\n",
    "    \n",
    "    for _ in range(n_epochs):\n",
    "        acc, loss = train(\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimiser,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "    model = model.to('cpu')\n",
    "    torch.quantization.convert(model, inplace=True)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e171d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as transformsv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73ef6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_cifar10_train_val_loaders, ROOT_DIR, DEFAULT_TRANSFORM, print_size_of_model, subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a08d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.579704\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported qscheme: per_channel_affine",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m         optimizer.step()\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Convert to quantized model after training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Now, the model is quantized and can be used for inference.\u001b[39;00m\n\u001b[32m     64\u001b[39m print_size_of_model(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:657\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[32m    656\u001b[39m     module = copy.deepcopy(module)\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remove_qconfig:\n\u001b[32m    666\u001b[39m     _remove_qconfig(module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:722\u001b[39m, in \u001b[36m_convert\u001b[39m\u001b[34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule)\n\u001b[32m    712\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping\n\u001b[32m    713\u001b[39m     ):\n\u001b[32m    714\u001b[39m         _convert(\n\u001b[32m    715\u001b[39m             mod,\n\u001b[32m    716\u001b[39m             mapping,\n\u001b[32m   (...)\u001b[39m\u001b[32m    720\u001b[39m             use_precomputed_fake_quant=use_precomputed_fake_quant,\n\u001b[32m    721\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m     reassign[name] = \u001b[43mswap_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_module_class_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign.items():\n\u001b[32m    727\u001b[39m     module._modules[key] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:764\u001b[39m, in \u001b[36mswap_module\u001b[39m\u001b[34m(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    762\u001b[39m sig = inspect.signature(qmod.from_float)\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_precomputed_fake_quant\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sig.parameters:\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     new_mod = \u001b[43mqmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    768\u001b[39m     new_mod = qmod.from_float(mod)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:606\u001b[39m, in \u001b[36mConv2d.from_float\u001b[39m\u001b[34m(cls, mod, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    599\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_float\u001b[39m(\u001b[38;5;28mcls\u001b[39m, mod, use_precomputed_fake_quant=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    600\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001b[39;00m\n\u001b[32m    601\u001b[39m \n\u001b[32m    602\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[33;03m        mod (Module): a float module, either produced by torch.ao.quantization\u001b[39;00m\n\u001b[32m    604\u001b[39m \u001b[33;03m          utilities or provided by the user\u001b[39;00m\n\u001b[32m    605\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConvNd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:322\u001b[39m, in \u001b[36m_ConvNd.from_float\u001b[39m\u001b[34m(cls, mod, use_precomputed_fake_quant)\u001b[39m\n\u001b[32m    320\u001b[39m         mod = mod[\u001b[32m0\u001b[39m]\n\u001b[32m    321\u001b[39m     weight_post_process = mod.qconfig.weight()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_qconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_post_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_post_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:266\u001b[39m, in \u001b[36m_ConvNd.get_qconv\u001b[39m\u001b[34m(cls, mod, activation_post_process, weight_post_process)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[39;00m\n\u001b[32m    255\u001b[39m qconv = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    256\u001b[39m     mod.in_channels,\n\u001b[32m    257\u001b[39m     mod.out_channels,\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m     mod.padding_mode,\n\u001b[32m    265\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mqconv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_weight_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    268\u001b[39m     activation_post_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m activation_post_process.dtype == torch.float\n\u001b[32m    270\u001b[39m ):\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m qconv  \u001b[38;5;66;03m# dynamic quantization doesn't need scale/zero_point\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:567\u001b[39m, in \u001b[36mConv2d.set_weight_bias\u001b[39m\u001b[34m(self, w, b)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_weight_bias\u001b[39m(\u001b[38;5;28mself\u001b[39m, w: torch.Tensor, b: Optional[torch.Tensor]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode == \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m         \u001b[38;5;28mself\u001b[39m._packed_params = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantized\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d_prepack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m            \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    571\u001b[39m         \u001b[38;5;28mself\u001b[39m._packed_params = torch.ops.quantized.conv2d_prepack(\n\u001b[32m    572\u001b[39m             w, b, \u001b[38;5;28mself\u001b[39m.stride, _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    573\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/users/local/b24richa/EDL/.venv/lib/python3.12/site-packages/torch/_ops.py:1123\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsupported qscheme: per_channel_affine"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "train_loader, val_loader = get_cifar10_train_val_loaders(subset=True, num_subset=5000)\n",
    "\n",
    "\n",
    "# Download CIFAR-10 dataset (train and test)\n",
    "train_dataset = subset_data(CIFAR10(root=ROOT_DIR, train=True, download=True, transform=DEFAULT_TRANSFORM), 5000)\n",
    "test_dataset = CIFAR10(root=ROOT_DIR, train=False, download=True, transform=DEFAULT_TRANSFORM)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# Define a simple model (e.g., for QAT)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 30 * 30, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, move to CUDA\n",
    "model = SimpleModel().to('cuda')\n",
    "\n",
    "print_size_of_model(model)\n",
    "\n",
    "# QAT preparation\n",
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "torch.quantization.prepare_qat(model, inplace=True)\n",
    "\n",
    "# Set up optimizer and criterion\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Example epochs\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:  # Assuming a DataLoader `train_loader`\n",
    "        inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Convert to quantized model after training\n",
    "torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "# Now, the model is quantized and can be used for inference.\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e895a536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (conv1): QuantizedConv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.06295403838157654, zero_point=63)\n",
       "  (fc1): QuantizedLinear(in_features=14400, out_features=10, scale=0.1440950483083725, zero_point=59, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to('cpu')  # Move the model back to CPU for conversion\n",
    "torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd1d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.148866\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdc0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f388ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 0.148866\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
